{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voxtral vLLM BYOC Deployment on SageMaker\n",
    "\n",
    "This notebook demonstrates how to deploy Mistral AI's Voxtral models using a custom vLLM container (BYOC - Bring Your Own Container) on Amazon SageMaker.\n",
    "\n",
    "## Overview\n",
    "- **Models**: Voxtral-Mini-3B-2507 and Voxtral-Small-24B-2507\n",
    "- **Engine**: vLLM v0.10.0+ (required for Voxtral support)\n",
    "- **Deployment**: Custom Docker container with BYOC approach\n",
    "- **Features**: Multimodal audio+text processing, function calling (Small model), transcription\n",
    "- **Context**: 32k token context length, up to 30min audio transcription, 40min audio understanding\n",
    "\n",
    "## Key Advantages of BYOC Approach\n",
    "1. **Latest vLLM version** - Control over vLLM version (v0.10.0+) with Voxtral support\n",
    "2. **Official configurations** - Uses official Voxtral server parameters\n",
    "3. **Full control** - Complete control over container environment and dependencies\n",
    "4. **Future-proof** - Easy updates to new vLLM versions\n",
    "5. **Flexible architecture** - Separate container image from model code for faster iterations\n",
    "\n",
    "## Supported Models\n",
    "- **Voxtral-Mini-3B-2507**: Text + audio processing, ml.g6.4xlarge instance\n",
    "- **Voxtral-Small-24B-2507**: Text + audio + function calling, ml.g6.12xlarge instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:05:18.774485Z",
     "iopub.status.busy": "2025-10-13T11:05:18.774139Z",
     "iopub.status.idle": "2025-10-13T11:05:18.777147Z",
     "shell.execute_reply": "2025-10-13T11:05:18.776706Z",
     "shell.execute_reply.started": "2025-10-13T11:05:18.774469Z"
    }
   },
   "outputs": [],
   "source": [
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies\n",
    "\n",
    "Install required packages and initialize SageMaker session.\n",
    "\n",
    "**Prerequisites**: Docker image should be built and pushed before running this notebook. See README for build instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for SageMaker BYOC deployment\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "# Initialize SageMaker session and get execution role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()  # IAM role for SageMaker operations\n",
    "bucket = \"<your-s3-bucket>\"  # S3 bucket for storing model artifacts\n",
    "\n",
    "# Get AWS account and region information\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()['Account']\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "print(f\"AWS Account ID: {account_id}\")\n",
    "print(f\"AWS Region: {region}\")\n",
    "print(f\"SageMaker role: {role}\")\n",
    "print(f\"S3 bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Container Configuration\n",
    "\n",
    "Configure the custom container image URI. The Docker image should be pre-built with vLLM v0.10.0+ and base dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T11:05:24.673470Z",
     "iopub.status.busy": "2025-10-13T11:05:24.672899Z",
     "iopub.status.idle": "2025-10-13T11:05:24.676365Z",
     "shell.execute_reply": "2025-10-13T11:05:24.675936Z",
     "shell.execute_reply.started": "2025-10-13T11:05:24.673454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom container will be built and pushed to:\n",
      "Repository: voxtral-vllm-byoc\n",
      "Image URI: 459006231907.dkr.ecr.us-west-2.amazonaws.com/voxtral-vllm-byoc:latest\n"
     ]
    }
   ],
   "source": [
    "# Configuration for custom container\n",
    "repository_name = \"voxtral-vllm-byoc\"\n",
    "image_tag = \"latest\"\n",
    "image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{repository_name}:{image_tag}\"\n",
    "\n",
    "print(f\"Custom container will be built and pushed to:\")\n",
    "print(f\"Repository: {repository_name}\")\n",
    "print(f\"Image URI: {image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T12:58:56.736277Z",
     "iopub.status.busy": "2025-10-13T12:58:56.735673Z",
     "iopub.status.idle": "2025-10-13T12:58:56.741045Z",
     "shell.execute_reply": "2025-10-13T12:58:56.740625Z",
     "shell.execute_reply.started": "2025-10-13T12:58:56.736262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ BYOC model artifacts ready:\n",
      "  âœ… model.py (31504 bytes)\n",
      "  âœ… serving.properties (2581 bytes)\n",
      "  âœ… requirements.txt (831 bytes)\n"
     ]
    }
   ],
   "source": [
    "# Prepare BYOC model artifacts from code directory\n",
    "# Files are already organized in the code/ directory structure\n",
    "byoc_code_dir = \"./code\"\n",
    "\n",
    "# Verify required files exist in code directory\n",
    "required_files = [\"model.py\", \"serving.properties\", \"requirements.txt\"]\n",
    "missing_files = []\n",
    "\n",
    "for file in required_files:\n",
    "    file_path = os.path.join(byoc_code_dir, file)\n",
    "    if not os.path.exists(file_path):\n",
    "        missing_files.append(file_path)\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"âŒ Missing required files: {missing_files}\")\n",
    "    print(\"Please ensure all files are in the code/ directory.\")\n",
    "else:\n",
    "    print(\"ğŸ“ BYOC model artifacts ready:\")\n",
    "    for file in required_files:\n",
    "        file_path = os.path.join(byoc_code_dir, file)\n",
    "        if os.path.exists(file_path):\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            print(f\"  âœ… {file} ({file_size} bytes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload BYOC configuration to S3\n",
    "prefix = \"voxtral-vllm-byoc\"  # Se bucket folder prefix\n",
    "\n",
    "byoc_config_uri = sagemaker_session.upload_data(\n",
    "    path=byoc_code_dir, \n",
    "    bucket=bucket, \n",
    "    key_prefix=f\"{prefix}/code\"\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“¤ BYOC configuration uploaded to: {byoc_config_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy Custom vLLM Model on SageMaker\n",
    "\n",
    "Create a real-time inference endpoint using the custom vLLM container.\n",
    "\n",
    "**Note**: Docker build and push should be completed before running this notebook. See README for build instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for SageMaker BYOC deployment\n",
    "timestamp = int(time.time())\n",
    "model_name = f'voxtral-vllm-byoc-model-{timestamp}'\n",
    "endpoint_name = f'voxtral-vllm-byoc-endpoint-{timestamp}'\n",
    "\n",
    "print(f\"Model name: {model_name}\")\n",
    "print(f\"Endpoint name: {endpoint_name}\")\n",
    "print(f\"Custom container image: {image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model data configuration for BYOC\n",
    "model_data = {\n",
    "    \"S3DataSource\": {\n",
    "        \"S3Uri\": f\"{byoc_config_uri}/\",\n",
    "        \"S3DataType\": \"S3Prefix\",\n",
    "        \"CompressionType\": \"None\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Model data configuration: {json.dumps(model_data, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T12:59:05.328573Z",
     "iopub.status.busy": "2025-10-13T12:59:05.328097Z",
     "iopub.status.idle": "2025-10-13T12:59:05.331676Z",
     "shell.execute_reply": "2025-10-13T12:59:05.331166Z",
     "shell.execute_reply.started": "2025-10-13T12:59:05.328557Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create SageMaker model configuration for custom vLLM container\n",
    "voxtral_byoc_model = Model(\n",
    "    image_uri=image_uri,  # Use our custom container\n",
    "    model_data=model_data,  # Contains model.py, serving.properties, requirements.txt\n",
    "    role=role,\n",
    "    name=model_name,\n",
    "    env={\n",
    "        # Environment variables for our custom container\n",
    "        'MODEL_CACHE_DIR': '/opt/ml/model',\n",
    "        'TRANSFORMERS_CACHE': '/tmp/transformers_cache',\n",
    "        'HF_HOME': '/tmp/hf_home',\n",
    "        'VLLM_WORKER_MULTIPROC_METHOD': 'spawn',\n",
    "        'SAGEMAKER_BIND_TO_PORT': '8080',\n",
    "        'SAGEMAKER_BIND_TO_HOST': '0.0.0.0'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T12:59:07.358866Z",
     "iopub.status.busy": "2025-10-13T12:59:07.358004Z",
     "iopub.status.idle": "2025-10-13T13:07:40.683517Z",
     "shell.execute_reply": "2025-10-13T13:07:40.683047Z",
     "shell.execute_reply.started": "2025-10-13T12:59:07.358826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Deploying BYOC vLLM endpoint: voxtral-vllm-byoc-endpoint-1760360341\n",
      "This will take approximately 8-10 minutes...\n",
      "----------------!âœ… BYOC vLLM Endpoint deployed successfully: voxtral-vllm-byoc-endpoint-1760360341\n",
      "CPU times: user 348 ms, sys: 4.69 ms, total: 353 ms\n",
      "Wall time: 8min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Deploy the custom vLLM model to a real-time inference endpoint\n",
    "print(f\"ğŸš€ Deploying BYOC vLLM endpoint: {endpoint_name}\")\n",
    "print(\"This will take approximately 8-10 minutes...\")\n",
    "\n",
    "try:\n",
    "    predictor = voxtral_byoc_model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.g6.12xlarge\",    # For Voxtral-Mini: use ml.g6.4xlarge, for Voxtral-Small: use ml.g6.12xlarge     \n",
    "        endpoint_name=endpoint_name,\n",
    "        serializer=JSONSerializer(),\n",
    "        deserializer=JSONDeserializer(),\n",
    "        container_startup_health_check_timeout=1200,  # Extended timeout for model loading\n",
    "        model_data_download_timeout=1800,\n",
    "        wait=True\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… BYOC vLLM Endpoint deployed successfully: {endpoint_name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Deployment failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Custom vLLM Deployment\n",
    "\n",
    "Test the deployed model with various input types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Test Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T13:09:23.055543Z",
     "iopub.status.busy": "2025-10-13T13:09:23.055108Z",
     "iopub.status.idle": "2025-10-13T13:09:24.851729Z",
     "shell.execute_reply": "2025-10-13T13:09:24.851217Z",
     "shell.execute_reply.started": "2025-10-13T13:09:23.055523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Testing endpoint health...\n",
      "Response: Hello! Yes, I'm here and ready to assist you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# Test endpoint health\n",
    "\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "try:\n",
    "    # Simple health check payload\n",
    "    health_payload = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Hello, are you working?\"\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 50,\n",
    "        \"temperature\": 0.1\n",
    "    }\n",
    "    \n",
    "    print(\"ğŸ” Testing endpoint health...\")\n",
    "    response = predictor.predict(health_payload)\n",
    "    print(f\"Response: {response['choices'][0]['message']['content']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Health check failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Text-Only Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T13:10:04.047652Z",
     "iopub.status.busy": "2025-10-13T13:10:04.047442Z",
     "iopub.status.idle": "2025-10-13T13:10:13.809361Z",
     "shell.execute_reply": "2025-10-13T13:10:13.808845Z",
     "shell.execute_reply.started": "2025-10-13T13:10:04.047637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¤ Testing text-only conversation with custom vLLM...\n",
      "Response: Hello! I'd be happy to explain the advantages of using vLLM (Virtual Large Language Model) for model inference.\n",
      "\n",
      "1. **Scalability**: vLLM is designed to handle large language models efficiently. It can scale to models with billions of parameters, making it suitable for tasks that require high computational resources.\n",
      "\n",
      "2. **Efficiency**: vLLM uses a technique called \"virtual memory\" to manage the model's parameters. This allows it to use less physical memory than traditional methods, making it more efficient and reducing the cost of inference.\n",
      "\n",
      "3. **Speed**: vLLM can perform inference faster than many other methods. It achieves this by using a combination of techniques, including model parallelism and pipelining.\n",
      "\n",
      "4. **Flexibility**: vLLM supports a wide range of models and can be used for various tasks, such as text generation, translation, and summarization.\n",
      "\n",
      "5. **Ease of Use**: vLLM is designed to be easy to use.\n",
      "\n",
      "ğŸ“Š Token Usage:\n",
      "  Prompt tokens: 21\n",
      "  Completion tokens: 200\n",
      "  Total tokens: 221\n"
     ]
    }
   ],
   "source": [
    "# Test text-only conversation using OpenAI format\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hello! Can you tell me about the advantages of using vLLM for model inference?\"\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 200,\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.95\n",
    "}\n",
    "\n",
    "print(\"ğŸ”¤ Testing text-only conversation with custom vLLM...\")\n",
    "try:\n",
    "    response = predictor.predict(payload)\n",
    "    print(\"Response:\", response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    \n",
    "    # Print usage statistics if available\n",
    "    if \"usage\" in response:\n",
    "        usage = response[\"usage\"]\n",
    "        print(f\"\\nğŸ“Š Token Usage:\")\n",
    "        print(f\"  Prompt tokens: {usage.get('prompt_tokens', 'N/A')}\")\n",
    "        print(f\"  Completion tokens: {usage.get('completion_tokens', 'N/A')}\")\n",
    "        print(f\"  Total tokens: {usage.get('total_tokens', 'N/A')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Text conversation test failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Audio Understanding Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T13:10:13.810296Z",
     "iopub.status.busy": "2025-10-13T13:10:13.810090Z",
     "iopub.status.idle": "2025-10-13T13:10:18.897293Z",
     "shell.execute_reply": "2025-10-13T13:10:18.896469Z",
     "shell.execute_reply.started": "2025-10-13T13:10:13.810281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸµ Testing audio file url for transcription...\n",
      "Response: And the 0-1 pitch on the way to Edgar Martinez, swung on and lined down the left field line for a base hit. Here comes Joey, here is Junior to third base, they're going to wave him in. The throw to the plate will be late. The Mariners are going to play for the American League Championship. I don't believe it. It just continues. My, oh my.\n",
      "\n",
      "ğŸ“Š Token Usage:\n",
      "  Prompt tokens: 384\n",
      "  Completion tokens: 85\n",
      "  Total tokens: 469\n"
     ]
    }
   ],
   "source": [
    "# Test audio file url for transcription\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Transcribe this audio file\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"audio\",\n",
    "                    \"path\": \"https://huggingface.co/datasets/hf-internal-testing/dummy-audio-samples/resolve/main/winning_call.mp3\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 300,\n",
    "    \"temperature\": 0.0,  # Use 0.0 for transcription tasks\n",
    "    \"top_p\": 0.95\n",
    "}\n",
    "\n",
    "print(\"ğŸµ Testing audio file url for transcription...\")\n",
    "try:\n",
    "    response = predictor.predict(payload)\n",
    "    print(\"Response:\", response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    \n",
    "    # Print usage statistics if available\n",
    "    if \"usage\" in response:\n",
    "        usage = response[\"usage\"]\n",
    "        print(f\"\\nğŸ“Š Token Usage:\")\n",
    "        print(f\"  Prompt tokens: {usage.get('prompt_tokens', 'N/A')}\")\n",
    "        print(f\"  Completion tokens: {usage.get('completion_tokens', 'N/A')}\")\n",
    "        print(f\"  Total tokens: {usage.get('total_tokens', 'N/A')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Audio file url test failed: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T13:10:24.381502Z",
     "iopub.status.busy": "2025-10-13T13:10:24.380628Z",
     "iopub.status.idle": "2025-10-13T13:10:30.043586Z",
     "shell.execute_reply": "2025-10-13T13:10:30.043104Z",
     "shell.execute_reply.started": "2025-10-13T13:10:24.381450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸµ Testing audio file base64 for audio understanding...\n",
      "Response: The audio describes a dramatic moment in a baseball game. Here's a breakdown:\n",
      "\n",
      "- The pitcher throws a pitch to Edgar Martinez.\n",
      "- Martinez hits the ball, which goes down the left field line for a base hit.\n",
      "- Joy and Junior advance to third base and home plate, respectively.\n",
      "- The throw to home plate is late, allowing Junior to score.\n",
      "- The Mariners win the game and advance to the American League Championship.\n",
      "- The announcer expresses disbelief and excitement about the Mariners' victory.\n",
      "\n",
      "ğŸ“Š Token Usage:\n",
      "  Prompt tokens: 387\n",
      "  Completion tokens: 103\n",
      "  Total tokens: 490\n"
     ]
    }
   ],
   "source": [
    "# Test audio file base64 for audio understanding\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Load audio file and encode as base64\n",
    "with open(\"winning_call.mp3\", \"rb\") as audio_file:\n",
    "    audio_data = base64.b64encode(audio_file.read()).decode('utf-8')\n",
    "\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What do you hear in this audio?\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"audio\",\n",
    "                    \"data\": f\"data:audio/mp3;base64,{audio_data}\"  # Base64 encoded audio\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 300,\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.95\n",
    "}\n",
    "\n",
    "print(\"ğŸµ Testing audio file base64 for audio understanding...\")\n",
    "\n",
    "try:\n",
    "    response = predictor.predict(payload)\n",
    "    print(\"Response:\", response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    \n",
    "    # Print usage statistics if available\n",
    "    if \"usage\" in response:\n",
    "        usage = response[\"usage\"]\n",
    "        print(f\"\\nğŸ“Š Token Usage:\")\n",
    "        print(f\"  Prompt tokens: {usage.get('prompt_tokens', 'N/A')}\")\n",
    "        print(f\"  Completion tokens: {usage.get('completion_tokens', 'N/A')}\")\n",
    "        print(f\"  Total tokens: {usage.get('total_tokens', 'N/A')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Audio file base64 test failed: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Multiple Audio Files Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T12:37:40.896953Z",
     "iopub.status.busy": "2025-10-13T12:37:40.896492Z",
     "iopub.status.idle": "2025-10-13T12:37:46.590977Z",
     "shell.execute_reply": "2025-10-13T12:37:46.590490Z",
     "shell.execute_reply.started": "2025-10-13T12:37:40.896934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸµ Testing multiple audio files support...\n",
      "Response: Both audio files contain spoken words, but they differ significantly in content and context. The first audio file is a historical speech by Thomas Edison, where he recites a nursery rhyme. The second audio file is a sports commentary, describing a baseball game and the excitement of a team winning the American League Championship. The similarities lie in the fact that both are spoken English, but the differences are in the subject matter and the emotional tone.\n"
     ]
    }
   ],
   "source": [
    "# Test with multiple audio files \n",
    "multi_audio_payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"audio\",\n",
    "                    \"path\": \"https://huggingface.co/datasets/hf-internal-testing/dummy-audio-samples/resolve/main/mary_had_lamb.mp3\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"audio\", \n",
    "                    \"path\": \"https://huggingface.co/datasets/hf-internal-testing/dummy-audio-samples/resolve/main/winning_call.mp3\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Compare these two audio files. What similarities and differences do you notice?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 400,\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.95\n",
    "}\n",
    "\n",
    "print(\"ğŸµ Testing multiple audio files support...\")\n",
    "try:\n",
    "    response = predictor.predict(multi_audio_payload)\n",
    "    print(\"Response:\", response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Multiple audio test failed: {str(e)}\")\n",
    "    print(\"ğŸ’¡ This is expected if the model doesn't support multimodal processing yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Transcribe-only mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T13:11:38.437348Z",
     "iopub.status.busy": "2025-10-13T13:11:38.436905Z",
     "iopub.status.idle": "2025-10-13T13:12:01.364503Z",
     "shell.execute_reply": "2025-10-13T13:12:01.363996Z",
     "shell.execute_reply.started": "2025-10-13T13:11:38.437328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸµ Testing transcribe-only mode...\n",
      "Transcribed: Chapitre 2 Slow Recording Et toi, tu es franÃ§ais ? Nous sommes dans l'Eurostar qui va de Londres Ã  Paris. Marie, une jeune Anglaise, parle avec Pierre, un jeune FranÃ§ais qui est assis Ã  cÃ´tÃ© d'elle. Marie. Et toi ? Tu es franÃ§ais, n'est-ce pas ? Pierre. Oui, je viens d'aller Ã  Londres pour voir des amis. Mais je suis franÃ§ais. Marie. Et donc, tu parles aussi anglais ? Pierre. Vraiment, je ne parle pas trÃ¨s bien anglais. J'ai un accent horrible. Marie. Est-ce que tu vas souvent Ã  Londres ? Pierre. Non, malheureusement, pas trÃ¨s souvent. Et toi, pourquoi vas-tu Ã  Paris aujourd'hui ? Marie. Je vais travailler Ã  Paris pendant trois mois. Pierre. Ah oui, vraiment ? C'est super ! Tu vas faire quoi ? Marie. Je vais Ãªtre jeune fille au pÃ¨re. Pierre. Et tu connais dÃ©jÃ  la famille pour laquelle tu vas travailler ? Marie. Non, pas vraiment. Nous sommes amis sur Facebook. Donc, je connais un peu leurs habitudes. Ils ont l'air trÃ¨s gentils. Pierre. Et tu vas t'occuper de plusieurs enfants ? Marie. Non, juste un. Un petit garÃ§on de 8 ans. Il s'appelle Paul. Pierre. Et lui aussi, il est bilingue ? Marie. Non, pas du tout. Mais il apprend un peu d'anglais Ã  l'Ã©cole. Et toi, tu fais quoi ? Pierre. Moi, je suis en troisiÃ¨me annÃ©e de droit. Marie. Et oÃ¹ est-ce que tu Ã©tudies ? Pierre. Ã€ l'universitÃ© Dauphine.\n"
     ]
    }
   ],
   "source": [
    "# test English transcription with file: https://huggingface.co/datasets/hf-internal-testing/dummy-audio-samples/resolve/main/obama.mp3\n",
    "\n",
    "print(\"ğŸµ Testing transcribe-only mode...\")\n",
    "\n",
    "# transcription payload\n",
    "payload = {\n",
    "  \"transcription\": {\n",
    "      \"audio\": \"https://audiocdn.frenchtoday.com/file/ft-public-files/audiobook-samples/AMPFE/AMP%20FE%20Ch%2002%20Story%20Slower.mp3\",  # or URL or base64\n",
    "      \"language\": \"fr\",               \n",
    "      \"temperature\": 0.0              \n",
    "  }\n",
    "}\n",
    "\n",
    "# Make prediction\n",
    "response = predictor.predict(payload)\n",
    "transcribed_text = response[\"transcription\"][\"text\"]\n",
    "print(f\"Transcribed: {transcribed_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Function calling - only supported by Voxtral Small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T13:12:08.768797Z",
     "iopub.status.busy": "2025-10-13T13:12:08.768391Z",
     "iopub.status.idle": "2025-10-13T13:12:11.746625Z",
     "shell.execute_reply": "2025-10-13T13:12:11.746146Z",
     "shell.execute_reply.started": "2025-10-13T13:12:08.768781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing Function Calling...\n",
      "Response: I'll help you with that.\n",
      "ğŸ”§ Tool calls found:\n",
      "  Function: get_current_weather\n",
      "  Args: {'location': 'Madrid', 'format': 'celsius'}\n",
      "  Result: It's sunny in Madrid with 25Â°C\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define weather tool configuration\n",
    "WEATHER_TOOL = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather for a specific location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Mock weather function\n",
    "def mock_weather(location, format=\"celsius\"):\n",
    "    \"\"\"Always returns sunny weather at 25Â°C/77Â°F\"\"\"\n",
    "    temp = 77 if format.lower() == \"fahrenheit\" else 25\n",
    "    unit = \"Â°F\" if format.lower() == \"fahrenheit\" else \"Â°C\"\n",
    "    return f\"It's sunny in {location} with {temp}{unit}\"\n",
    "\n",
    "# Test payload with audio\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                \"type\": \"audio\",\n",
    "                \"path\": \"https://huggingface.co/datasets/patrickvonplaten/audio_samples/resolve/main/fn_calling.wav\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.95,\n",
    "    \"tools\": [WEATHER_TOOL]\n",
    "}\n",
    "\n",
    "\n",
    "print(\"ğŸ§ª Testing Function Calling...\")\n",
    "try:\n",
    "    # Try audio first, then text if that fails\n",
    "    response = predictor.predict(payload)\n",
    "\n",
    "    message = response[\"choices\"][0][\"message\"]\n",
    "    print(f\"Response: {message['content']}\")\n",
    "\n",
    "    # Check for tool calls\n",
    "    if \"tool_calls\" in message:\n",
    "        print(\"ğŸ”§ Tool calls found:\")\n",
    "        for tool_call in message[\"tool_calls\"]:\n",
    "            func_name = tool_call[\"function\"][\"name\"]\n",
    "            func_args = json.loads(tool_call[\"function\"][\"arguments\"])\n",
    "            print(f\"  Function: {func_name}\")\n",
    "            print(f\"  Args: {func_args}\")\n",
    "\n",
    "            # Execute mock function\n",
    "            if func_name == \"get_current_weather\":\n",
    "                result = mock_weather(**func_args)\n",
    "                print(f\"  Result: {result}\")\n",
    "    else:\n",
    "        print(\"âŒ No tool calls found\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Integration with Strands Agents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U strands-agents strands-agents-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pydantic==2.11.7 mypy_boto3_sagemaker_runtime openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T13:12:19.995895Z",
     "iopub.status.busy": "2025-10-13T13:12:19.995482Z",
     "iopub.status.idle": "2025-10-13T13:12:20.051399Z",
     "shell.execute_reply": "2025-10-13T13:12:20.050920Z",
     "shell.execute_reply.started": "2025-10-13T13:12:19.995877Z"
    }
   },
   "outputs": [],
   "source": [
    "# SageMaker integration with Strands agents \n",
    "# from strands import Agent\n",
    "from strands import Agent\n",
    "from strands.models.sagemaker import SageMakerAIModel\n",
    "from strands_tools import calculator, current_time, file_read, shell\n",
    "\n",
    "model = SageMakerAIModel(\n",
    "    endpoint_config={\n",
    "        \"endpoint_name\": endpoint_name,\n",
    "        \"region_name\": \"us-west-2\",\n",
    "    },\n",
    "    payload_config={\n",
    "        \"max_tokens\": 1000,\n",
    "        \"temperature\": 0.7,\n",
    "        \"stream\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "agent = Agent(model=model, tools=[calculator, current_time, file_read, shell])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T13:12:22.014846Z",
     "iopub.status.busy": "2025-10-13T13:12:22.014456Z",
     "iopub.status.idle": "2025-10-13T13:12:26.221387Z",
     "shell.execute_reply": "2025-10-13T13:12:26.220909Z",
     "shell.execute_reply.started": "2025-10-13T13:12:22.014828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll help you with that.\n",
      "Tool #1: calculator\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Calculation Result</span><span style=\"color: #000080; text-decoration-color: #000080\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Operation </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> Evaluate Expression </span>â”‚                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Input     </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> sqrt(12)            </span>â”‚                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Result    </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> 3.4641016151        </span>â”‚                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mâ•­â”€\u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mCalculation Result\u001b[0m\u001b[34m \u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34mâ”€â•®\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m                                                                                                                 \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â”‚\u001b[36m \u001b[0m\u001b[36mOperation\u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mEvaluate Expression\u001b[0m\u001b[32m \u001b[0mâ”‚                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â”‚\u001b[36m \u001b[0m\u001b[36mInput    \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32msqrt(12)           \u001b[0m\u001b[32m \u001b[0mâ”‚                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â”‚\u001b[36m \u001b[0m\u001b[36mResult   \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32m3.4641016151       \u001b[0m\u001b[32m \u001b[0mâ”‚                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m                                                                                                                 \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The square root of 12 is approximately 3.4641016151."
     ]
    }
   ],
   "source": [
    "response = agent(\"What is the square root of 12?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T13:12:27.853819Z",
     "iopub.status.busy": "2025-10-13T13:12:27.853217Z",
     "iopub.status.idle": "2025-10-13T13:12:35.041495Z",
     "shell.execute_reply": "2025-10-13T13:12:35.041054Z",
     "shell.execute_reply.started": "2025-10-13T13:12:27.853804Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll help you with that.\n",
      "Tool #2: file_read\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">ğŸ“„ requirements.txt</span><span style=\"color: #000080; text-decoration-color: #000080\"> â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 1 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># Additional Python dependencies for Voxtral vLLM container</span><span style=\"background-color: #272822\">             </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 2 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># Core dependencies are installed in Dockerfile, these are supplementary</span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 3 </span><span style=\"background-color: #272822\">                                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 4 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># API and web framework dependencies</span><span style=\"background-color: #272822\">                                    </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 5 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">fastapi&gt;=0.115.0</span><span style=\"background-color: #272822\">                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 6 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">uvicorn[standard]&gt;=0.32.0</span><span style=\"background-color: #272822\">                                               </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 7 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">gunicorn&gt;=23.0.0</span><span style=\"background-color: #272822\">                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 8 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">pydantic&gt;=2.0.0</span><span style=\"background-color: #272822\">                                                         </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 9 </span><span style=\"background-color: #272822\">                                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">10 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># OpenAI client for vLLM integration</span><span style=\"background-color: #272822\">                                    </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">11 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">openai&gt;=1.0.0</span><span style=\"background-color: #272822\">                                                           </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">12 </span><span style=\"background-color: #272822\">                                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">13 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># Mistral Common for audio processing and transcription</span><span style=\"background-color: #272822\">                 </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">14 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">mistral_common[audio]&gt;=1.8.1</span><span style=\"background-color: #272822\">                                            </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">15 </span><span style=\"background-color: #272822\">                                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">16 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># HTTP and networking</span><span style=\"background-color: #272822\">                                                   </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">17 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">httpx&gt;=0.27.0</span><span style=\"background-color: #272822\">                                                           </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">18 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">aiohttp&gt;=3.10.0</span><span style=\"background-color: #272822\">                                                         </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">19 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">websockets&gt;=13.0</span><span style=\"background-color: #272822\">                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">20 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">requests&gt;=2.31.0</span><span style=\"background-color: #272822\">                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">21 </span><span style=\"background-color: #272822\">                                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">22 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># Audio processing (additional libraries)</span><span style=\"background-color: #272822\">                               </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">23 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">scipy&gt;=1.14.0</span><span style=\"background-color: #272822\">                                                           </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">24 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">numpy&gt;=1.26.0</span><span style=\"background-color: #272822\">                                                           </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">25 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">resampy&gt;=0.4.3</span><span style=\"background-color: #272822\">                                                          </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">26 </span><span style=\"background-color: #272822\">                                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">27 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># Utilities</span><span style=\"background-color: #272822\">                                                             </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">28 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">python-multipart&gt;=0.0.12</span><span style=\"background-color: #272822\">                                                </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">29 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">python-json-logger&gt;=2.0.7</span><span style=\"background-color: #272822\">                                               </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">30 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">psutil&gt;=6.0.0</span><span style=\"background-color: #272822\">                                                           </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">31 </span><span style=\"background-color: #272822\">                                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">32 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># AWS and cloud integrations</span><span style=\"background-color: #272822\">                                            </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">33 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">aioboto3&gt;=13.0.0</span><span style=\"background-color: #272822\">                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">34 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">aiobotocore&gt;=2.15.0</span><span style=\"background-color: #272822\">                                                     </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">35 </span><span style=\"background-color: #272822\">                                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">36 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># Development and debugging (optional)</span><span style=\"background-color: #272822\">                                  </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">37 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">ipython&gt;=8.28.0</span><span style=\"background-color: #272822\">                                                         </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">38 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">jupyter&gt;=1.1.1</span><span style=\"background-color: #272822\">                                                          </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">39 </span><span style=\"background-color: #272822\">                                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">40 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># Monitoring and observability</span><span style=\"background-color: #272822\">                                          </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">41 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">prometheus-client&gt;=0.21.0</span><span style=\"background-color: #272822\">                                               </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mâ•”â•\u001b[0m\u001b[34mâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mğŸ“„ requirements.txt\u001b[0m\u001b[34m \u001b[0m\u001b[34mâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\u001b[0m\u001b[34mâ•â•—\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m                                                                                 \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 1 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# Additional Python dependencies for Voxtral vLLM container\u001b[0m\u001b[48;2;39;40;34m             \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 2 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# Core dependencies are installed in Dockerfile, these are supplementary\u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 3 \u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 4 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# API and web framework dependencies\u001b[0m\u001b[48;2;39;40;34m                                    \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 5 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfastapi>=0.115.0\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 6 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34muvicorn[standard]>=0.32.0\u001b[0m\u001b[48;2;39;40;34m                                               \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 7 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mgunicorn>=23.0.0\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 8 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpydantic>=2.0.0\u001b[0m\u001b[48;2;39;40;34m                                                         \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 9 \u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m10 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# OpenAI client for vLLM integration\u001b[0m\u001b[48;2;39;40;34m                                    \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m11 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mopenai>=1.0.0\u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m12 \u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m13 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# Mistral Common for audio processing and transcription\u001b[0m\u001b[48;2;39;40;34m                 \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m14 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmistral_common[audio]>=1.8.1\u001b[0m\u001b[48;2;39;40;34m                                            \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m15 \u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m16 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# HTTP and networking\u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m17 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mhttpx>=0.27.0\u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m18 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34maiohttp>=3.10.0\u001b[0m\u001b[48;2;39;40;34m                                                         \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m19 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwebsockets>=13.0\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m20 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrequests>=2.31.0\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m21 \u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m22 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# Audio processing (additional libraries)\u001b[0m\u001b[48;2;39;40;34m                               \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m23 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mscipy>=1.14.0\u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m24 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnumpy>=1.26.0\u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m25 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresampy>=0.4.3\u001b[0m\u001b[48;2;39;40;34m                                                          \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m26 \u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m27 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# Utilities\u001b[0m\u001b[48;2;39;40;34m                                                             \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m28 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpython-multipart>=0.0.12\u001b[0m\u001b[48;2;39;40;34m                                                \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m29 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpython-json-logger>=2.0.7\u001b[0m\u001b[48;2;39;40;34m                                               \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m30 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpsutil>=6.0.0\u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m31 \u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m32 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# AWS and cloud integrations\u001b[0m\u001b[48;2;39;40;34m                                            \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m33 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34maioboto3>=13.0.0\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m34 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34maiobotocore>=2.15.0\u001b[0m\u001b[48;2;39;40;34m                                                     \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m35 \u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m36 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# Development and debugging (optional)\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m37 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mipython>=8.28.0\u001b[0m\u001b[48;2;39;40;34m                                                         \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m38 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mjupyter>=1.1.1\u001b[0m\u001b[48;2;39;40;34m                                                          \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m39 \u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m40 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# Monitoring and observability\u001b[0m\u001b[48;2;39;40;34m                                          \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m41 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprometheus-client>=0.21.0\u001b[0m\u001b[48;2;39;40;34m                                               \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m                                                                                 \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the contents of the requirements.txt file in the current directory. It lists the additional Python dependencies required for the Voxtral vLLM container, including API and web framework dependencies, OpenAI client for vLLM integration, Mistral Common for audio processing and transcription, HTTP and networking libraries, audio processing libraries, utilities, AWS and cloud integrations, development and debugging tools, and monitoring and observability tools."
     ]
    }
   ],
   "source": [
    "response = agent(\"Show me the contents of requirements.txt in this directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cleanup Resources\n",
    "\n",
    "**Important**: Remember to delete resources when done to avoid charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—‘ï¸ Deleting endpoint: voxtral-vllm-byoc-endpoint-1755863967\n",
      "âœ… Endpoint deleted successfully\n"
     ]
    }
   ],
   "source": [
    "# Delete SageMaker endpoint\n",
    "print(f\"ğŸ—‘ï¸ Deleting endpoint: {endpoint_name}\")\n",
    "predictor.delete_endpoint(delete_endpoint_config=True)\n",
    "print(\"âœ… Endpoint deleted successfully\")\n",
    "\n",
    "\n",
    "# # Delete ECR repository (optional)\n",
    "# ecr_client = boto3.client('ecr')\n",
    "# ecr_client.delete_repository(\n",
    "#     repositoryName='voxtral-vllm-byoc',\n",
    "#     force=True\n",
    "# )\n",
    "# print(\"âœ… ECR repository deleted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "1. **âœ… Flexible BYOC Architecture** - Separated container image from model code\n",
    "2. **âœ… Dynamic Code Deployment** - Model artifacts provided via S3 model_data\n",
    "3. **âœ… Multi-Model Support** - Both Voxtral Mini and Small models supported\n",
    "4. **âœ… SageMaker Integration** - Custom model and endpoint creation\n",
    "5. **âœ… Multimodal Processing** - Audio + text processing with proper formatting\n",
    "6. **âœ… Function Calling** - Tool calling support for Voxtral-Small model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
