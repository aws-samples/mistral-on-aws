{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voxtral vLLM BYOC Deployment on SageMaker\n",
    "\n",
    "This notebook demonstrates how to deploy Mistral AI's Voxtral models using a custom vLLM container (BYOC - Bring Your Own Container) on Amazon SageMaker.\n",
    "\n",
    "## Overview\n",
    "- **Models**: Voxtral-Mini-3B-2507 and Voxtral-Small-24B-2507\n",
    "- **Engine**: vLLM v0.10.0+ (required for Voxtral support)\n",
    "- **Deployment**: Custom Docker container with BYOC approach\n",
    "- **Features**: Multimodal audio+text processing, function calling (Small model), transcription\n",
    "- **Context**: 32k token context length, up to 30min audio transcription, 40min audio understanding\n",
    "\n",
    "## Key Advantages of BYOC Approach\n",
    "1. **Latest vLLM version** - Control over vLLM version (v0.10.0+) with Voxtral support\n",
    "2. **Official configurations** - Uses official Voxtral server parameters\n",
    "3. **Full control** - Complete control over container environment and dependencies\n",
    "4. **Future-proof** - Easy updates to new vLLM versions\n",
    "5. **Flexible architecture** - Separate container image from model code for faster iterations\n",
    "\n",
    "## Supported Models\n",
    "- **Voxtral-Mini-3B-2507**: Text + audio processing, ml.g6.4xlarge instance\n",
    "- **Voxtral-Small-24B-2507**: Text + audio + function calling, ml.g6.12xlarge instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies\n",
    "\n",
    "Install required packages and initialize SageMaker session.\n",
    "\n",
    "**Prerequisites**: Docker image should be built and pushed before running this notebook. See README for build instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for SageMaker BYOC deployment\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "# Initialize SageMaker session and get execution role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()  # IAM role for SageMaker operations\n",
    "# role = \"arn:aws:iam::459006231907:role/service-role/AmazonSageMaker-ExecutionRole-20250606T154579\" \n",
    "bucket = \"3p-projects\"  # S3 bucket for storing model artifacts\n",
    "\n",
    "# Get AWS account and region information\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()['Account']\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "print(f\"AWS Account ID: {account_id}\")\n",
    "print(f\"AWS Region: {region}\")\n",
    "print(f\"SageMaker role: {role}\")\n",
    "print(f\"S3 bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Container Configuration\n",
    "\n",
    "Configure the custom container image URI. The Docker image should be pre-built with vLLM v0.10.0+ and base dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom container will be built and pushed to:\n",
      "Repository: voxtral-vllm-byoc\n",
      "Image URI: 459006231907.dkr.ecr.us-west-2.amazonaws.com/voxtral-vllm-byoc:latest\n"
     ]
    }
   ],
   "source": [
    "# Configuration for custom container\n",
    "repository_name = \"voxtral-vllm-byoc\"\n",
    "image_tag = \"latest\"\n",
    "image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{repository_name}:{image_tag}\"\n",
    "\n",
    "print(f\"Custom container will be built and pushed to:\")\n",
    "print(f\"Repository: {repository_name}\")\n",
    "print(f\"Image URI: {image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ BYOC model artifacts ready:\n",
      "  âœ… model.py (34386 bytes)\n",
      "  âœ… serving.properties (2581 bytes)\n",
      "  âœ… requirements.txt (693 bytes)\n"
     ]
    }
   ],
   "source": [
    "# Prepare BYOC model artifacts from code directory\n",
    "# Files are already organized in the code/ directory structure\n",
    "byoc_code_dir = \"./code\"\n",
    "\n",
    "# Verify required files exist in code directory\n",
    "required_files = [\"model.py\", \"serving.properties\", \"requirements.txt\"]\n",
    "missing_files = []\n",
    "\n",
    "for file in required_files:\n",
    "    file_path = os.path.join(byoc_code_dir, file)\n",
    "    if not os.path.exists(file_path):\n",
    "        missing_files.append(file_path)\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"âŒ Missing required files: {missing_files}\")\n",
    "    print(\"Please ensure all files are in the code/ directory.\")\n",
    "else:\n",
    "    print(\"ğŸ“ BYOC model artifacts ready:\")\n",
    "    for file in required_files:\n",
    "        file_path = os.path.join(byoc_code_dir, file)\n",
    "        if os.path.exists(file_path):\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            print(f\"  âœ… {file} ({file_size} bytes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¤ BYOC configuration uploaded to: s3://3p-projects/voxtral-vllm-byoc/code\n"
     ]
    }
   ],
   "source": [
    "# Upload BYOC configuration to S3\n",
    "prefix = \"voxtral-vllm-byoc\"  # Se bucket folder prefix\n",
    "\n",
    "byoc_config_uri = sagemaker_session.upload_data(\n",
    "    path=byoc_code_dir, \n",
    "    bucket=bucket, \n",
    "    key_prefix=f\"{prefix}/code\"\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“¤ BYOC configuration uploaded to: {byoc_config_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy Custom vLLM Model on SageMaker\n",
    "\n",
    "Create a real-time inference endpoint using the custom vLLM container.\n",
    "\n",
    "**Note**: Docker build and push should be completed before running this notebook. See README for build instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: voxtral-vllm-byoc-model-1756738306\n",
      "Endpoint name: voxtral-vllm-byoc-endpoint-1756738306\n",
      "Custom container image: 459006231907.dkr.ecr.us-west-2.amazonaws.com/voxtral-vllm-byoc:latest\n",
      "\n",
      "ğŸ“‹ Instance recommendations:\n",
      "  - Voxtral-Mini-3B-2507: ml.g6.4xlarge (tensor_parallel_degree=1)\n",
      "  - Voxtral-Small-24B-2507: ml.g6.12xlarge (tensor_parallel_degree=4)\n"
     ]
    }
   ],
   "source": [
    "# Configuration for SageMaker BYOC deployment\n",
    "timestamp = int(time.time())\n",
    "model_name = f'voxtral-vllm-byoc-model-{timestamp}'\n",
    "endpoint_name = f'voxtral-vllm-byoc-endpoint-{timestamp}'\n",
    "\n",
    "print(f\"Model name: {model_name}\")\n",
    "print(f\"Endpoint name: {endpoint_name}\")\n",
    "print(f\"Custom container image: {image_uri}\")\n",
    "print(f\"\\nğŸ“‹ Instance recommendations:\")\n",
    "print(f\"  - Voxtral-Mini-3B-2507: ml.g6.4xlarge (tensor_parallel_degree=1)\")\n",
    "print(f\"  - Voxtral-Small-24B-2507: ml.g6.12xlarge (tensor_parallel_degree=4)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model data configuration: {\n",
      "  \"S3DataSource\": {\n",
      "    \"S3Uri\": \"s3://3p-projects/voxtral-vllm-byoc/code/\",\n",
      "    \"S3DataType\": \"S3Prefix\",\n",
      "    \"CompressionType\": \"None\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Prepare model data configuration for BYOC\n",
    "model_data = {\n",
    "    \"S3DataSource\": {\n",
    "        \"S3Uri\": f\"{byoc_config_uri}/\",\n",
    "        \"S3DataType\": \"S3Prefix\",\n",
    "        \"CompressionType\": \"None\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Model data configuration: {json.dumps(model_data, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SageMaker model configuration for custom vLLM container\n",
    "voxtral_byoc_model = Model(\n",
    "    image_uri=image_uri,  # Use our custom container\n",
    "    model_data=model_data,  # Contains model.py, serving.properties, requirements.txt\n",
    "    role=role,\n",
    "    name=model_name,\n",
    "    env={\n",
    "        # Environment variables for our custom container\n",
    "        'MODEL_CACHE_DIR': '/opt/ml/model',\n",
    "        'TRANSFORMERS_CACHE': '/tmp/transformers_cache',\n",
    "        'HF_HOME': '/tmp/hf_home',\n",
    "        'VLLM_WORKER_MULTIPROC_METHOD': 'spawn',\n",
    "        'SAGEMAKER_BIND_TO_PORT': '8080',\n",
    "        'SAGEMAKER_BIND_TO_HOST': '0.0.0.0'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Deploying BYOC vLLM endpoint: voxtral-vllm-byoc-endpoint-1756738306\n",
      "This will take approximately 8-10 minutes...\n",
      "----------------!âœ… BYOC vLLM Endpoint deployed successfully: voxtral-vllm-byoc-endpoint-1756738306\n",
      "CPU times: user 189 ms, sys: 17.9 ms, total: 207 ms\n",
      "Wall time: 8min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Deploy the custom vLLM model to a real-time inference endpoint\n",
    "print(f\"ğŸš€ Deploying BYOC vLLM endpoint: {endpoint_name}\")\n",
    "print(\"This will take approximately 8-10 minutes...\")\n",
    "\n",
    "try:\n",
    "    predictor = voxtral_byoc_model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.g6.12xlarge\",    # For Voxtral-Mini: use ml.g6.4xlarge, for Voxtral-Small: use ml.g6.12xlarge     \n",
    "        endpoint_name=endpoint_name,\n",
    "        serializer=JSONSerializer(),\n",
    "        deserializer=JSONDeserializer(),\n",
    "        container_startup_health_check_timeout=1200,  # Extended timeout for model loading\n",
    "        model_data_download_timeout=1800,\n",
    "        wait=True\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… BYOC vLLM Endpoint deployed successfully: {endpoint_name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Deployment failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Custom vLLM Deployment\n",
    "\n",
    "Test the deployed model with various input types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Test Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Testing endpoint health...\n",
      "Response: Hello! Yes, I'm here and ready to assist you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# Test endpoint health\n",
    "\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "try:\n",
    "    # Simple health check payload\n",
    "    health_payload = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Hello, are you working?\"\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 50,\n",
    "        \"temperature\": 0.1\n",
    "    }\n",
    "    \n",
    "    print(\"ğŸ” Testing endpoint health...\")\n",
    "    response = predictor.predict(health_payload)\n",
    "    print(f\"Response: {response['choices'][0]['message']['content']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Health check failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Text-Only Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¤ Testing text-only conversation with custom vLLM...\n",
      "Response: Hello! I'd be happy to explain the advantages of using vLLM (Virtual Large Language Model) for model inference.\n",
      "\n",
      "1. **Scalability**: vLLM is designed to handle large language models efficiently. It can scale to models with billions of parameters, making it suitable for tasks that require high computational resources.\n",
      "\n",
      "2. **Efficiency**: vLLM uses a technique called \"virtual memory\" to manage the model's parameters. This allows it to use less physical memory than traditional methods, making it more efficient and reducing the cost of inference.\n",
      "\n",
      "3. **Speed**: vLLM can perform inference faster than many other methods. It achieves this by using a combination of techniques, including model parallelism and pipelining.\n",
      "\n",
      "4. **Flexibility**: vLLM supports a wide range of models and can be used for various tasks, such as text generation, translation, and summarization.\n",
      "\n",
      "5. **Ease of Use**: vLLM is designed to be easy to use.\n",
      "\n",
      "ğŸ“Š Token Usage:\n",
      "  Prompt tokens: 21\n",
      "  Completion tokens: 200\n",
      "  Total tokens: 221\n"
     ]
    }
   ],
   "source": [
    "# Test text-only conversation using OpenAI format\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hello! Can you tell me about the advantages of using vLLM for model inference?\"\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 200,\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.95\n",
    "}\n",
    "\n",
    "print(\"ğŸ”¤ Testing text-only conversation with custom vLLM...\")\n",
    "try:\n",
    "    response = predictor.predict(payload)\n",
    "    print(\"Response:\", response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    \n",
    "    # Print usage statistics if available\n",
    "    if \"usage\" in response:\n",
    "        usage = response[\"usage\"]\n",
    "        print(f\"\\nğŸ“Š Token Usage:\")\n",
    "        print(f\"  Prompt tokens: {usage.get('prompt_tokens', 'N/A')}\")\n",
    "        print(f\"  Completion tokens: {usage.get('completion_tokens', 'N/A')}\")\n",
    "        print(f\"  Total tokens: {usage.get('total_tokens', 'N/A')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Text conversation test failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Audio Understanding Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸµ Testing audio file url for transcription...\n",
      "Response: And the 0-1 pitch on the way to Edgar Martinez, swung on and lined down the left field line for a base hit. Here comes Joey. Here is Junior to third base. They're going to wave him in. The throw to the plate will be late. The Mariners are going to play for the American League Championship. I don't believe it. It just continues. My, oh my.\n",
      "\n",
      "ğŸ“Š Token Usage:\n",
      "  Prompt tokens: 384\n",
      "  Completion tokens: 85\n",
      "  Total tokens: 469\n"
     ]
    }
   ],
   "source": [
    "# Test audio file url for transcription\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Transcribe this audio file\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"audio\",\n",
    "                    \"path\": \"https://huggingface.co/datasets/hf-internal-testing/dummy-audio-samples/resolve/main/winning_call.mp3\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 300,\n",
    "    \"temperature\": 0.0,  # Use 0.0 for transcription tasks\n",
    "    \"top_p\": 0.95\n",
    "}\n",
    "\n",
    "print(\"ğŸµ Testing audio file url for transcription...\")\n",
    "try:\n",
    "    response = predictor.predict(payload)\n",
    "    print(\"Response:\", response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    \n",
    "    # Print usage statistics if available\n",
    "    if \"usage\" in response:\n",
    "        usage = response[\"usage\"]\n",
    "        print(f\"\\nğŸ“Š Token Usage:\")\n",
    "        print(f\"  Prompt tokens: {usage.get('prompt_tokens', 'N/A')}\")\n",
    "        print(f\"  Completion tokens: {usage.get('completion_tokens', 'N/A')}\")\n",
    "        print(f\"  Total tokens: {usage.get('total_tokens', 'N/A')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Audio file url test failed: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸµ Testing audio file base64 for audio understanding...\n",
      "Response: The audio describes a dramatic moment in a baseball game. Here's a breakdown:\n",
      "\n",
      "- The pitcher throws a pitch to Edgar Martinez.\n",
      "- Martinez hits the ball, which goes down the left field line for a base hit.\n",
      "- Jay Buhner (referred to as \"Joy\" in the audio) and Ken Griffey Jr. (referred to as \"Junior\") advance to third base and home plate, respectively.\n",
      "- The throw to the plate is late, allowing Griffey Jr. to score.\n",
      "- This play allows the Seattle Mariners to advance to the American League Championship.\n",
      "\n",
      "The commentator expresses disbelief and excitement about the Mariners' advancement.\n",
      "\n",
      "ğŸ“Š Token Usage:\n",
      "  Prompt tokens: 387\n",
      "  Completion tokens: 133\n",
      "  Total tokens: 520\n"
     ]
    }
   ],
   "source": [
    "# Test audio file base64 for audio understanding\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Load audio file and encode as base64\n",
    "with open(\"winning_call.mp3\", \"rb\") as audio_file:\n",
    "    audio_data = base64.b64encode(audio_file.read()).decode('utf-8')\n",
    "\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What do you hear in this audio?\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"audio\",\n",
    "                    \"data\": f\"data:audio/mp3;base64,{audio_data}\"  # Base64 encoded audio\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 300,\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.95\n",
    "}\n",
    "\n",
    "print(\"ğŸµ Testing audio file base64 for audio understanding...\")\n",
    "\n",
    "try:\n",
    "    response = predictor.predict(payload)\n",
    "    print(\"Response:\", response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    \n",
    "    # Print usage statistics if available\n",
    "    if \"usage\" in response:\n",
    "        usage = response[\"usage\"]\n",
    "        print(f\"\\nğŸ“Š Token Usage:\")\n",
    "        print(f\"  Prompt tokens: {usage.get('prompt_tokens', 'N/A')}\")\n",
    "        print(f\"  Completion tokens: {usage.get('completion_tokens', 'N/A')}\")\n",
    "        print(f\"  Total tokens: {usage.get('total_tokens', 'N/A')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Audio file base64 test failed: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Multiple Audio Files Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸµ Testing multiple audio files support...\n",
      "Response: The first audio is a historical speech by Thomas Edison, where he recites a nursery rhyme, \"Mary Had a Little Lamb,\" which was the first words he spoke into the phonograph. The second audio is a sports commentary, specifically a baseball game, where the commentator describes a play that leads to a significant win for the Mariners. The similarities are that both audios involve a historical moment being described, but the differences lie in the content and context, with one being a technological milestone and the other a sports achievement.\n"
     ]
    }
   ],
   "source": [
    "# Test with multiple audio files \n",
    "multi_audio_payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"audio\",\n",
    "                    \"path\": \"https://huggingface.co/datasets/hf-internal-testing/dummy-audio-samples/resolve/main/mary_had_lamb.mp3\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"audio\", \n",
    "                    \"path\": \"https://huggingface.co/datasets/hf-internal-testing/dummy-audio-samples/resolve/main/winning_call.mp3\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Compare these two audio files. What similarities and differences do you notice?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 400,\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.95\n",
    "}\n",
    "\n",
    "print(\"ğŸµ Testing multiple audio files support...\")\n",
    "try:\n",
    "    response = predictor.predict(multi_audio_payload)\n",
    "    print(\"Response:\", response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Multiple audio test failed: {str(e)}\")\n",
    "    print(\"ğŸ’¡ This is expected if the model doesn't support multimodal processing yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Transcribe-only mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸµ Testing transcribe-only mode...\n",
      "Response: This week, I traveled to Chicago to deliver my final farewell address to the nation, following in the tradition of presidents before me. It was an opportunity to say thank you. Whether we've seen eye to eye or rarely agreed at all, my conversations with you, the American people, in living rooms and schools, at farms and on factory floors, at diners and on distant military outposts, all these conversations are what have kept me honest, kept me inspired, and kept me going. Every day, I learned from you. You made me a better president, and you made me a better man. Over the course of these eight years, I've seen the goodness, the resilience, and the hope of the American people. I've seen neighbors looking out for each other as we rescued our economy from the worst crisis of our lifetimes. I've hugged cancer survivors who finally know the security of affordable health care. I've seen communities like Joplin rebuild from disaster and cities like Boston show the world that no terrorist will ever break the American spirit. I've seen the hopeful faces of young graduates and our newest military officers. I've mourned with grieving families searching for answers, and I found grace in a Charleston church. I've seen our scientists help a paralyzed man regain his sense of touch and our wounded warriors walk again. I've seen our doctors and volunteers rebuild after earthquakes and stop pandemics in their tracks. I've learned from students who are\n"
     ]
    }
   ],
   "source": [
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"audio\",\n",
    "                    \"path\": \"https://huggingface.co/datasets/hf-internal-testing/dummy-audio-samples/resolve/main/obama.mp3\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 300,\n",
    "    \"temperature\": 0.0, #Â set temperature as 0 for transcribe-only mode\n",
    "    \"top_p\": 0.95,\n",
    "}\n",
    "\n",
    "print(\"ğŸµ Testing transcribe-only mode...\")\n",
    "try:\n",
    "    response = predictor.predict(payload)\n",
    "    print(\"Response:\", response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Transcribe-only test failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Function calling - only supported by Voxtral Small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing Function Calling...\n",
      "Response: I'll help you with that.\n",
      "ğŸ”§ Tool calls found:\n",
      "  Function: get_current_weather\n",
      "  Args: {'location': 'Madrid', 'format': 'celsius'}\n",
      "  Result: It's sunny in Madrid with 25Â°C\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define weather tool configuration\n",
    "WEATHER_TOOL = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather for a specific location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Mock weather function\n",
    "def mock_weather(location, format=\"celsius\"):\n",
    "    \"\"\"Always returns sunny weather at 25Â°C/77Â°F\"\"\"\n",
    "    temp = 77 if format.lower() == \"fahrenheit\" else 25\n",
    "    unit = \"Â°F\" if format.lower() == \"fahrenheit\" else \"Â°C\"\n",
    "    return f\"It's sunny in {location} with {temp}{unit}\"\n",
    "\n",
    "# Test payload with audio\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                \"type\": \"audio\",\n",
    "                \"path\": \"https://huggingface.co/datasets/patrickvonplaten/audio_samples/resolve/main/fn_calling.wav\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.95,\n",
    "    \"tools\": [WEATHER_TOOL]\n",
    "}\n",
    "\n",
    "\n",
    "print(\"ğŸ§ª Testing Function Calling...\")\n",
    "try:\n",
    "    # Try audio first, then text if that fails\n",
    "    response = predictor.predict(payload)\n",
    "\n",
    "    message = response[\"choices\"][0][\"message\"]\n",
    "    print(f\"Response: {message['content']}\")\n",
    "\n",
    "    # Check for tool calls\n",
    "    if \"tool_calls\" in message:\n",
    "        print(\"ğŸ”§ Tool calls found:\")\n",
    "        for tool_call in message[\"tool_calls\"]:\n",
    "            func_name = tool_call[\"function\"][\"name\"]\n",
    "            func_args = json.loads(tool_call[\"function\"][\"arguments\"])\n",
    "            print(f\"  Function: {func_name}\")\n",
    "            print(f\"  Args: {func_args}\")\n",
    "\n",
    "            # Execute mock function\n",
    "            if func_name == \"get_current_weather\":\n",
    "                result = mock_weather(**func_args)\n",
    "                print(f\"  Result: {result}\")\n",
    "    else:\n",
    "        print(\"âŒ No tool calls found\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Integration with Strands Agents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U strands-agents strands-agents-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pydantic==2.11.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker integration with Strands agents \n",
    "# from strands import Agent\n",
    "from strands import Agent\n",
    "from strands.models.sagemaker import SageMakerAIModel\n",
    "from strands_tools import calculator, current_time, file_read, shell\n",
    "\n",
    "model = SageMakerAIModel(\n",
    "    endpoint_config={\n",
    "        \"endpoint_name\": endpoint_name,\n",
    "        \"region_name\": \"us-west-2\",\n",
    "    },\n",
    "    payload_config={\n",
    "        \"max_tokens\": 1000,\n",
    "        \"temperature\": 0.7,\n",
    "        \"stream\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "agent = Agent(model=model, tools=[calculator, current_time, file_read, shell])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll help you with that.\n",
      "Tool #1: calculator\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Calculation Result</span><span style=\"color: #000080; text-decoration-color: #000080\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Operation </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> Evaluate Expression </span>â”‚                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Input     </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> sqrt(12)            </span>â”‚                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Result    </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> 3.4641016151        </span>â”‚                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯                                                                            <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mâ•­â”€\u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mCalculation Result\u001b[0m\u001b[34m \u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34mâ”€â•®\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m                                                                                                                 \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â”‚\u001b[36m \u001b[0m\u001b[36mOperation\u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mEvaluate Expression\u001b[0m\u001b[32m \u001b[0mâ”‚                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â”‚\u001b[36m \u001b[0m\u001b[36mInput    \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32msqrt(12)           \u001b[0m\u001b[32m \u001b[0mâ”‚                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â”‚\u001b[36m \u001b[0m\u001b[36mResult   \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32m3.4641016151       \u001b[0m\u001b[32m \u001b[0mâ”‚                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯                                                                            \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m                                                                                                                 \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The square root of 12 is approximately 3.464."
     ]
    }
   ],
   "source": [
    "response = agent(\"What is the square root of 12?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll help you with that.\n",
      "Tool #4: file_read\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">ğŸ“„ requirements.txt</span><span style=\"color: #000080; text-decoration-color: #000080\"> â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 1 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># Additional Python dependencies for Voxtral vLLM container</span><span style=\"background-color: #272822\">             </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 2 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># Core dependencies are installed in Dockerfile, these are supplementary</span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 3 </span><span style=\"background-color: #272822\">                                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 4 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># API and web framework dependencies</span><span style=\"background-color: #272822\">                                    </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 5 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">fastapi&gt;=0.115.0</span><span style=\"background-color: #272822\">                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 6 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">uvicorn[standard]&gt;=0.32.0</span><span style=\"background-color: #272822\">                                               </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 7 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">gunicorn&gt;=23.0.0</span><span style=\"background-color: #272822\">                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 8 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">pydantic&gt;=2.0.0</span><span style=\"background-color: #272822\">                                                         </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 9 </span><span style=\"background-color: #272822\">                                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">10 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># HTTP and networking</span><span style=\"background-color: #272822\">                                                   </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">11 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">httpx&gt;=0.27.0</span><span style=\"background-color: #272822\">                                                           </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">12 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">aiohttp&gt;=3.10.0</span><span style=\"background-color: #272822\">                                                         </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">13 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">websockets&gt;=13.0</span><span style=\"background-color: #272822\">                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">14 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">requests&gt;=2.31.0</span><span style=\"background-color: #272822\">                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">15 </span><span style=\"background-color: #272822\">                                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">16 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># Audio processing (additional libraries)</span><span style=\"background-color: #272822\">                               </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">17 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">scipy&gt;=1.14.0</span><span style=\"background-color: #272822\">                                                           </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">18 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">numpy&gt;=1.26.0</span><span style=\"background-color: #272822\">                                                           </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">19 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">resampy&gt;=0.4.3</span><span style=\"background-color: #272822\">                                                          </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">20 </span><span style=\"background-color: #272822\">                                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">21 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># Utilities</span><span style=\"background-color: #272822\">                                                             </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">22 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">python-multipart&gt;=0.0.12</span><span style=\"background-color: #272822\">                                                </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">23 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">python-json-logger&gt;=2.0.7</span><span style=\"background-color: #272822\">                                               </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">24 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">psutil&gt;=6.0.0</span><span style=\"background-color: #272822\">                                                           </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">25 </span><span style=\"background-color: #272822\">                                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">26 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># AWS and cloud integrations</span><span style=\"background-color: #272822\">                                            </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">27 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">aioboto3&gt;=13.0.0</span><span style=\"background-color: #272822\">                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">28 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">aiobotocore&gt;=2.15.0</span><span style=\"background-color: #272822\">                                                     </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">29 </span><span style=\"background-color: #272822\">                                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">30 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># Development and debugging (optional)</span><span style=\"background-color: #272822\">                                  </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">31 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">ipython&gt;=8.28.0</span><span style=\"background-color: #272822\">                                                         </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">32 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">jupyter&gt;=1.1.1</span><span style=\"background-color: #272822\">                                                          </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">33 </span><span style=\"background-color: #272822\">                                                                        </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">34 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"># Monitoring and observability</span><span style=\"background-color: #272822\">                                          </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>  <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">35 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">prometheus-client&gt;=0.21.0</span><span style=\"background-color: #272822\">                                               </span>  <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">â•‘</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mâ•”â•\u001b[0m\u001b[34mâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mğŸ“„ requirements.txt\u001b[0m\u001b[34m \u001b[0m\u001b[34mâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\u001b[0m\u001b[34mâ•â•—\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m                                                                                 \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 1 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# Additional Python dependencies for Voxtral vLLM container\u001b[0m\u001b[48;2;39;40;34m             \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 2 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# Core dependencies are installed in Dockerfile, these are supplementary\u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 3 \u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 4 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# API and web framework dependencies\u001b[0m\u001b[48;2;39;40;34m                                    \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 5 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfastapi>=0.115.0\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 6 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34muvicorn[standard]>=0.32.0\u001b[0m\u001b[48;2;39;40;34m                                               \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 7 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mgunicorn>=23.0.0\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 8 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpydantic>=2.0.0\u001b[0m\u001b[48;2;39;40;34m                                                         \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 9 \u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m10 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# HTTP and networking\u001b[0m\u001b[48;2;39;40;34m                                                   \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m11 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mhttpx>=0.27.0\u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m12 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34maiohttp>=3.10.0\u001b[0m\u001b[48;2;39;40;34m                                                         \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m13 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwebsockets>=13.0\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m14 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrequests>=2.31.0\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m15 \u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m16 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# Audio processing (additional libraries)\u001b[0m\u001b[48;2;39;40;34m                               \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m17 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mscipy>=1.14.0\u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m18 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnumpy>=1.26.0\u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m19 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mresampy>=0.4.3\u001b[0m\u001b[48;2;39;40;34m                                                          \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m20 \u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m21 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# Utilities\u001b[0m\u001b[48;2;39;40;34m                                                             \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m22 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpython-multipart>=0.0.12\u001b[0m\u001b[48;2;39;40;34m                                                \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m23 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpython-json-logger>=2.0.7\u001b[0m\u001b[48;2;39;40;34m                                               \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m24 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpsutil>=6.0.0\u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m25 \u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m26 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# AWS and cloud integrations\u001b[0m\u001b[48;2;39;40;34m                                            \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m27 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34maioboto3>=13.0.0\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m28 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34maiobotocore>=2.15.0\u001b[0m\u001b[48;2;39;40;34m                                                     \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m29 \u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m30 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# Development and debugging (optional)\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m31 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mipython>=8.28.0\u001b[0m\u001b[48;2;39;40;34m                                                         \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m32 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mjupyter>=1.1.1\u001b[0m\u001b[48;2;39;40;34m                                                          \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m33 \u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m34 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m# Monitoring and observability\u001b[0m\u001b[48;2;39;40;34m                                          \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m  \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m35 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprometheus-client>=0.21.0\u001b[0m\u001b[48;2;39;40;34m                                               \u001b[0m  \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•‘\u001b[0m                                                                                 \u001b[34mâ•‘\u001b[0m\n",
       "\u001b[34mâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The content of the requirements.txt file in this directory is:\n",
      "\n",
      "```plaintext\n",
      "# Additional Python dependencies for Voxtral vLLM container\n",
      "# Core dependencies are installed in Dockerfile, these are supplementary\n",
      "\n",
      "# API and web framework dependencies\n",
      "fastapi>=0.115.0\n",
      "uvicorn[standard]>=0.32.0\n",
      "gunicorn>=23.0.0\n",
      "pydantic>=2.0.0\n",
      "\n",
      "# HTTP and networking\n",
      "httpx>=0.27.0\n",
      "aiohttp>=3.10.0\n",
      "websockets>=13.0\n",
      "requests>=2.31.0\n",
      "\n",
      "# Audio processing (additional libraries)\n",
      "scipy>=1.14.0\n",
      "numpy>=1.26.0\n",
      "resampy>=0.4.3\n",
      "\n",
      "# Utilities\n",
      "python-multipart>=0.0.12\n",
      "python-json-logger>=2.0.7\n",
      "psutil>=6.0.0\n",
      "\n",
      "# AWS and cloud integrations\n",
      "aioboto3>=13.0.0\n",
      "aiobotocore>=2.15.0\n",
      "\n",
      "# Development and debugging (optional)\n",
      "ipython>=8.28.0\n",
      "jupyter>=1.1.1\n",
      "\n",
      "# Monitoring and observability\n",
      "prometheus-client>=0.21.0\n",
      "```"
     ]
    }
   ],
   "source": [
    "response = agent(\"Show me the contents of requirements.txt in this directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cleanup Resources\n",
    "\n",
    "**Important**: Remember to delete resources when done to avoid charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—‘ï¸ Deleting endpoint: voxtral-vllm-byoc-endpoint-1755863967\n",
      "âœ… Endpoint deleted successfully\n"
     ]
    }
   ],
   "source": [
    "# Delete SageMaker endpoint\n",
    "print(f\"ğŸ—‘ï¸ Deleting endpoint: {endpoint_name}\")\n",
    "predictor.delete_endpoint(delete_endpoint_config=True)\n",
    "print(\"âœ… Endpoint deleted successfully\")\n",
    "\n",
    "\n",
    "# # Delete ECR repository (optional)\n",
    "# ecr_client = boto3.client('ecr')\n",
    "# ecr_client.delete_repository(\n",
    "#     repositoryName='voxtral-vllm-byoc',\n",
    "#     force=True\n",
    "# )\n",
    "# print(\"âœ… ECR repository deleted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "1. **âœ… Flexible BYOC Architecture** - Separated container image from model code\n",
    "2. **âœ… Dynamic Code Deployment** - Model artifacts provided via S3 model_data\n",
    "3. **âœ… Multi-Model Support** - Both Voxtral Mini and Small models supported\n",
    "4. **âœ… SageMaker Integration** - Custom model and endpoint creation\n",
    "5. **âœ… Multimodal Processing** - Audio + text processing with proper formatting\n",
    "6. **âœ… Function Calling** - Tool calling support for Voxtral-Small model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
