{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Bedrock Mistral prompting examples","text":""},{"location":"#getting-started","title":"Getting Started \ud83d\ude80","text":"<p>Please visit Amazon Bedrock user guide on how to enable model access. \ud83d\udcda</p> <p>The notebooks are executed from SageMaker studio with Data Science 3.0 image. \ud83d\udcbb\ud83d\udd2c</p>"},{"location":"#introduction","title":"Introduction \ud83c\udf0d","text":"<p>Welcome to the Bedrock Mistral prompting examples repository! This collection aims to provide you with a wide range of prompting examples and techniques to enhance your experience with the Mistral language model. Whether you're a beginner or an experienced user, these examples will help you in your generative AI journey. \ud83d\udca1</p>"},{"location":"#resources","title":"Resources \ud83d\udcda","text":"<p>Looking for additional resources? Check out these helpful links:</p> <ul> <li>Mistral Documentation</li> <li>Bedrock Documentation</li> </ul>"},{"location":"notebooks/","title":"Main Notebooks \ud83d\udcda","text":"<ul> <li> <p>Mistral Getting Started Guide: \ud83d\ude80 This notebook adds tool use to the comprehensive guide on utilizing the Converse API with the Mistral models, focusing on defining tools, understanding tool_choice impacts, and leveraging the API for enhanced functionality. Users will learn to configure tools, observe the effects of different tool choices on model outputs, and gain practical experience with the Converse API to maximize the Mistral models' potential in various scenarios.</p> </li> <li> <p>Prompt Engineering 101 w/ Mistral: \ud83d\udee0\ufe0f This notebook provides a comprehensive guide on how to get started with the Mistral AI models on Amazon Bedrock. It highlights the significance of prompt engineering techniques, such as zero-shot, few-shot, and chain-of-thought prompting, to enhance the quality and accuracy of model outputs. The notebook demonstrates how to effectively utilize special tokens and instruction templates to maximize the potential of LLMs. Additionally, it offers a detailed comparison of the capabilities of Mistral Large, Mixtral 8x7B, and Mistral Small models, showcasing their respective strengths in analytical reasoning and multilingual tasks through insightful examples. Overall, the notebook equips users with the necessary knowledge and techniques to leverage the power of Mistral AI models on Amazon Bedrock effectively.</p> </li> <li> <p>OpenAI to Mistral: \ud83c\udf09 This guide provides a foundation for transitioning OpenAI prompts and workloads to Mistral models, demonstrating their capabilities and efficiency through practical examples.</p> </li> <li> <p>Agentic Workflows with tool use - now with native tool use!: \ud83e\udd16 We demonstrate an agentic workflow that leverages Mistral models on Amazon Bedrock to create a seamless function calling experience. We explore techniques for crafting effective prompts over function calling and developing custom helper functions capable of understanding an API's data structure. These helper functions can identify the necessary tools and methods to be executed during the agentic workflow interactions.</p> </li> <li> <p>Advanced RAG Pipeline with Q&amp;A Automation and Model Evaluation: \u2699\ufe0f This notebook automates and evaluates the RAG pipeline with Mistral 7B Instruct as the generator. It utilizes LlamaIndex and Ragas to automate Q&amp;A, generating questions based on your data, allowing you to test your RAG pipeline's performance on a diverse set of queries without manual effort. Additionally, it assesses performance metrics such as faithfulness, relevancy, correctness, semantic similarity, and others on tailored test sets, aiming to identify strengths, limitations, and areas for improvement in the pipeline.</p> </li> <li> <p>Summarizing long documents with LangChain: \ud83d\udcda This Python notebook explores summarizing long documents using the Mistral Large language model on Amazon Bedrock with the LangChain library. It covers three main summarization techniques: Stuff (passing the entire document to the model in a single call), Map Reduce (a scalable technique, splitting the document into chunks, summarizing each chunk in parallel, and combining these summaries), and Refine (an iterative approach, generating an initial summary and refining it with additional context from subsequent chunks). The notebook includes detailed code examples for each technique using LangChain's utilities and chains. It demonstrates loading PDF documents, splitting them into text chunks, and customizing prompt templates. Additionally, it showcases the Mistral model's multilingual capabilities by generating a summary in French.</p> </li> <li> <p>Multi-chain Routing in LangChain: \ud83d\udd00 This notebook demonstrates the use of multi-chain routing in LangChain, a Python library for building applications with large language models (LLMs) and integrating different Mistral AI models from Amazon Bedrock (Mistral Large, Mistral 7B, and Mixtral 8X7B). The notebook explores a use case in the Financial Services Industry (FSI), where a user can query information about their investments, retrieve financial reports, and search for relevant news articles using a single pipeline.</p> </li> </ul>"}]}