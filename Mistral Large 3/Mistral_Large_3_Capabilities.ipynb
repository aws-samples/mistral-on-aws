{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Mistral Large 3: Frontier Open-Source Multimodal Model on Amazon Bedrock\n\n---\n\n[Mistral Large 3](https://mistral.ai/news/mistral-3) represents a significant leap forward in open-source AI, introducing a powerful sparse Mixture-of-Experts (MoE) architecture with **41 billion active parameters** out of **675 billion total parameters**. Released under the Apache 2.0 license, this model delivers frontier-level performance while remaining fully open source.\n\n## Key Highlights\n\n- **Multimodal Capabilities**: Native image understanding enables vision-language tasks\n- **Multilingual Excellence**: Best-in-class performance across 40+ languages\n- **Efficient Architecture**: Sparse MoE design provides excellent performance-to-cost ratio\n- **Advanced Reasoning**: State-of-the-art conversational and reasoning capabilities\n- **Open Source**: Apache 2.0 license for commercial and non-commercial use\n\nIn this notebook, we demonstrate Mistral Large 3's capabilities using Amazon Bedrock, covering:\n\n1. Basic text generation and reasoning\n2. Multilingual capabilities\n3. Vision and multimodal understanding\n4. Complex reasoning tasks\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Card\n",
    "\n",
    "---\n",
    "\n",
    "| Specification | Details |\n",
    "|--------------|----------|\n",
    "| **Model ID** | `mistral.mistral-large-3-675b-instruct` |\n",
    "| **Architecture** | Sparse Mixture-of-Experts (MoE) |\n",
    "| **Active Parameters** | 41B |\n",
    "| **Total Parameters** | 675B |\n",
    "| **License** | Apache 2.0 |\n",
    "| **Multimodal** | Yes (Text + Vision) |\n",
    "| **Languages** | 40+ languages supported |\n",
    "| **Training Infrastructure** | 3000 NVIDIA H200 GPUs |\n",
    "\n",
    "### Performance\n",
    "\n",
    "- Ranks **#2** among open-source non-reasoning models\n",
    "- Achieves parity with best instruction-tuned open-weight models\n",
    "- Best-in-class multilingual conversation performance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "%pip install --upgrade --quiet boto3 botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODEL_ID = \"mistral.mistral-large-3-675b-instruct\"\n",
    "REGION = \"us-west-2\"  # Update based on model availability\n",
    "\n",
    "# Initialize Bedrock client\n",
    "bedrock_client = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=REGION\n",
    ")\n",
    "\n",
    "print(f\"Model ID: {MODEL_ID}\")\n",
    "print(f\"Region: {REGION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converse(messages, system_prompt=None, max_tokens=5000, temperature=0.1, tool_config=None):\n",
    "    \"\"\"\n",
    "    Helper function to interact with Mistral Large 3 using the Converse API.\n",
    "    \n",
    "    Args:\n",
    "        messages: List of message dictionaries with 'role' and 'content'\n",
    "        system_prompt: Optional system prompt string\n",
    "        max_tokens: Maximum tokens to generate\n",
    "        temperature: Sampling temperature (0.0 to 1.0)\n",
    "        tool_config: Optional tool configuration for function calling\n",
    "    \n",
    "    Returns:\n",
    "        Response from the model\n",
    "    \"\"\"\n",
    "    converse_params = {\n",
    "        \"modelId\": MODEL_ID,\n",
    "        \"messages\": messages,\n",
    "        \"inferenceConfig\": {\n",
    "            \"maxTokens\": max_tokens,\n",
    "            \"temperature\": temperature\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if system_prompt:\n",
    "        converse_params[\"system\"] = [{\"text\": system_prompt}]\n",
    "    \n",
    "    if tool_config:\n",
    "        converse_params[\"toolConfig\"] = tool_config\n",
    "    \n",
    "    response = bedrock_client.converse(**converse_params)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_text(response):\n",
    "    \"\"\"Extract text content from a Converse API response.\"\"\"\n",
    "    return response['output']['message']['content'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Basic Text Generation\n",
    "\n",
    "Let's start with basic text generation to demonstrate Mistral Large 3's capabilities.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple question answering\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": \"What are the key differences between supervised and unsupervised machine learning? Provide a concise explanation with examples.\"}]\n",
    "    }\n",
    "]\n",
    "\n",
    "response = converse(messages, temperature=0.3)\n",
    "print(get_response_text(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Generation\n",
    "\n",
    "Mistral Large 3 excels at code generation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_prompt = \"\"\"\n",
    "Write a Python function that implements a binary search algorithm. \n",
    "Include:\n",
    "1. Type hints\n",
    "2. Docstring with examples\n",
    "3. Handle edge cases\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [{\"text\": code_prompt}]}\n",
    "]\n",
    "\n",
    "response = converse(messages, temperature=0.1)\n",
    "print(get_response_text(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Multilingual Capabilities\n",
    "\n",
    "Mistral Large 3 supports 40+ languages with best-in-class multilingual conversation performance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation demonstration\n",
    "translation_prompt = \"\"\"\n",
    "Translate the following English text into French, German, Japanese, and Spanish:\n",
    "\n",
    "\"Artificial intelligence is transforming how we interact with technology, \n",
    "enabling more natural and intuitive experiences across all devices.\"\n",
    "\n",
    "Format each translation with the language name followed by the translation.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [{\"text\": translation_prompt}]}\n",
    "]\n",
    "\n",
    "response = converse(messages, temperature=0.3)\n",
    "print(get_response_text(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilingual conversation - responding in the same language as the query\n",
    "multilingual_queries = [\n",
    "    (\"French\", \"Expliquez-moi le concept de l'apprentissage automatique en termes simples.\"),\n",
    "    (\"Japanese\", \"クラウドコンピューティングの利点を簡単に説明してください。\"),\n",
    "    (\"Spanish\", \"¿Cuáles son las mejores prácticas para la seguridad en la nube?\")\n",
    "]\n",
    "\n",
    "for language, query in multilingual_queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Language: {language}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"text\": query}]}]\n",
    "    response = converse(messages, temperature=0.5)\n",
    "    print(f\"\\nResponse:\\n{get_response_text(response)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-lingual Analysis\n",
    "\n",
    "Analyze content in one language and respond in another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_lingual_prompt = \"\"\"\n",
    "Analyze the following German text and provide a summary in English:\n",
    "\n",
    "\"Die künstliche Intelligenz hat in den letzten Jahren enorme Fortschritte gemacht. \n",
    "Besonders im Bereich der Sprachverarbeitung und Bildererkennung wurden bedeutende \n",
    "Durchbrüche erzielt. Diese Technologien finden zunehmend Anwendung in verschiedenen \n",
    "Branchen, von der Medizin bis zur Automobilindustrie.\"\n",
    "\n",
    "Provide:\n",
    "1. English summary\n",
    "2. Key topics mentioned\n",
    "3. Sentiment analysis\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": [{\"text\": cross_lingual_prompt}]}]\n",
    "response = converse(messages, temperature=0.3)\n",
    "print(get_response_text(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Vision and Multimodal Understanding\n",
    "\n",
    "Mistral Large 3 features native image understanding capabilities. \n",
    "\n",
    "> **Note**: For vision tasks, use the **InvokeModel API** with Mistral's native message format. Converse API support for images is coming soon.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "def load_image_as_base64(image_path_or_url):\n",
    "    \"\"\"\n",
    "    Load an image from a file path or URL and convert to base64.\n",
    "    \n",
    "    Args:\n",
    "        image_path_or_url: Local file path or URL to the image\n",
    "    \n",
    "    Returns:\n",
    "        Base64 encoded string of the image\n",
    "    \"\"\"\n",
    "    if image_path_or_url.startswith(('http://', 'https://')):\n",
    "        req = urllib.request.Request(\n",
    "            image_path_or_url,\n",
    "            headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "        )\n",
    "        with urllib.request.urlopen(req) as response:\n",
    "            image_data = response.read()\n",
    "    else:\n",
    "        with open(image_path_or_url, 'rb') as f:\n",
    "            image_data = f.read()\n",
    "    \n",
    "    return base64.standard_b64encode(image_data).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image(image_source, prompt, media_type=\"image/jpeg\"):\n",
    "    \"\"\"\n",
    "    Analyze an image using Mistral Large 3's vision capabilities.\n",
    "    \n",
    "    Note: Vision requires using the InvokeModel API with Mistral's native format.\n",
    "    \n",
    "    Args:\n",
    "        image_source: File path or URL to the image\n",
    "        prompt: Text prompt describing what to analyze\n",
    "        media_type: MIME type of the image (default: image/jpeg)\n",
    "    \n",
    "    Returns:\n",
    "        Model's analysis of the image\n",
    "    \"\"\"\n",
    "    image_base64 = load_image_as_base64(image_source)\n",
    "    \n",
    "    # Mistral's native multimodal format using image_url with base64 data\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:{media_type};base64,{image_base64}\"\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 1024,\n",
    "        \"temperature\": 0.3\n",
    "    }\n",
    "    \n",
    "    response = bedrock_client.invoke_model(\n",
    "        modelId=MODEL_ID,\n",
    "        body=json.dumps(payload)\n",
    "    )\n",
    "    \n",
    "    result = json.loads(response['body'].read())\n",
    "    return result['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Analyze a financial chart\n",
    "image_path = \"../Pixtral-samples/Pixtral_data/Amazon_Chart.png\"\n",
    "\n",
    "analysis_prompt = \"\"\"Analyze this chart and provide:\n",
    "1. What type of data is being shown\n",
    "2. Key metrics and their values\n",
    "3. Notable trends or patterns\n",
    "\"\"\"\n",
    "\n",
    "result = analyze_image(image_path, analysis_prompt, media_type=\"image/png\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Image Analysis\n",
    "\n",
    "Analyze different types of images including photos, diagrams, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Analyze a data table image\n",
    "image_path = \"../Pixtral-samples/Pixtral_data/Crosstab_of_Cola_Preference_by_Age_and_Gender.png\"\n",
    "\n",
    "table_prompt = \"\"\"Analyze this table and provide:\n",
    "1. What data is being presented\n",
    "2. Extract the key values\n",
    "3. Any patterns or insights from the data\n",
    "\"\"\"\n",
    "\n",
    "result = analyze_image(image_path, table_prompt, media_type=\"image/png\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Complex Reasoning Tasks\n",
    "\n",
    "Mistral Large 3 demonstrates strong reasoning capabilities for multi-step problems.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical Reasoning - Probability Problem\n",
    "math_problem = \"\"\"\n",
    "A company has two factories. Factory A produces 60% of the total output, \n",
    "while Factory B produces 40%. The defect rate at Factory A is 2%, \n",
    "and at Factory B is 3%.\n",
    "\n",
    "1. What is the probability that a randomly selected product is defective?\n",
    "2. If a product is found to be defective, what is the probability it came from Factory A?\n",
    "\n",
    "Show your reasoning step by step.\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": [{\"text\": math_problem}]}]\n",
    "\n",
    "system_prompt = \"You are a mathematics expert. Solve problems step by step, showing all work clearly.\"\n",
    "\n",
    "response = converse(messages, system_prompt=system_prompt, temperature=0.1)\n",
    "print(get_response_text(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business Analysis and Strategic Decision Making\n",
    "business_analysis = \"\"\"\n",
    "You are advising a startup on their cloud infrastructure strategy. Consider the following scenario:\n",
    "\n",
    "Company Profile:\n",
    "- B2B SaaS product for data analytics\n",
    "- Current: 100 enterprise customers, expecting 3x growth in 18 months\n",
    "- Peak usage: 10 AM - 4 PM EST, weekdays\n",
    "- Data sensitivity: Financial and PII data\n",
    "- Current monthly cloud spend: $50,000\n",
    "- Engineering team: 15 developers, 2 DevOps engineers\n",
    "\n",
    "They're considering:\n",
    "A) Moving from multi-cloud to AWS-only to simplify operations\n",
    "B) Implementing Kubernetes for container orchestration\n",
    "C) Adopting a serverless-first architecture\n",
    "\n",
    "Provide a comprehensive analysis with:\n",
    "1. Pros and cons of each option\n",
    "2. Risk assessment\n",
    "3. Your recommended approach with justification\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": [{\"text\": business_analysis}]}]\n",
    "\n",
    "system_prompt = \"You are a senior cloud architect with expertise in enterprise infrastructure strategy.\"\n",
    "\n",
    "response = converse(messages, system_prompt=system_prompt, temperature=0.4, max_tokens=2500)\n",
    "print(get_response_text(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Mistral Large 3 represents a significant advancement in open-source AI models, combining:\n",
    "\n",
    "- **Frontier Performance**: Ranks among the top open-source models\n",
    "- **Multimodal Capabilities**: Native vision understanding for image analysis\n",
    "- **Multilingual Excellence**: 40+ language support with best-in-class performance\n",
    "- **Advanced Reasoning**: Strong mathematical, logical, and analytical capabilities\n",
    "- **Open Accessibility**: Apache 2.0 license for flexible deployment\n",
    "\n",
    "The combination of these capabilities with Amazon Bedrock's managed infrastructure makes Mistral Large 3 an excellent choice for enterprise applications requiring powerful, versatile, and cost-effective AI.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "\n",
    "This notebook uses Amazon Bedrock's serverless inference, so there are no resources to clean up. You are charged based on usage (input and output tokens processed)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}