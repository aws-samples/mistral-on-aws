{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistral Models on Amazon Bedrock - Converse API Tests\n",
    "\n",
    "This notebook uses the **Bedrock Converse API** (unified API) instead of invoke_model.\n",
    "\n",
    "Models tested:\n",
    "1. **Mistral Large 3** - Flagship multimodal model with reasoning\n",
    "2. **Ministral 3B** - Efficient small model\n",
    "3. **Ministral 8B** - Mid-size efficient model\n",
    "4. **Ministral 14B** - Larger efficient model\n",
    "5. **Voxtral Mini 3B** - Audio transcription model\n",
    "6. **Voxtral Small 24B** - Advanced audio model\n",
    "7. **Magistral Small 1.2** - Advanced reasoning model with vision (24B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet boto3 soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "\n",
    "# Initialize Bedrock Runtime client\n",
    "bedrock_runtime = boto3.client('bedrock-runtime', region_name='us-west-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converse_with_mistral(model_id, messages, system=None, max_tokens=2048, temperature=0.7, top_p=None, tools=None):\n",
    "    \"\"\"Invoke Mistral models using Converse API\"\"\"\n",
    "    request = {\n",
    "        \"modelId\": model_id,\n",
    "        \"messages\": messages,\n",
    "        \"inferenceConfig\": {\n",
    "            \"maxTokens\": max_tokens,\n",
    "            \"temperature\": temperature\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if top_p is not None:\n",
    "        request[\"inferenceConfig\"][\"topP\"] = top_p\n",
    "    \n",
    "    if system:\n",
    "        request[\"system\"] = [{\"text\": system}]\n",
    "    \n",
    "    if tools:\n",
    "        request[\"toolConfig\"] = {\n",
    "            \"tools\": tools,\n",
    "            \"toolChoice\": {\"auto\": {}}\n",
    "        }\n",
    "    \n",
    "    response = bedrock_runtime.converse(**request)\n",
    "    return response\n",
    "\n",
    "def print_response(response):\n",
    "    \"\"\"Pretty print Converse API response\"\"\"\n",
    "    if 'output' in response:\n",
    "        message = response['output']['message']\n",
    "        for content in message['content']:\n",
    "            if 'text' in content:\n",
    "                print(content['text'])\n",
    "            elif 'toolUse' in content:\n",
    "                tool_use = content['toolUse']\n",
    "                print(f\"Tool: {tool_use['name']}\")\n",
    "                print(f\"Input: {json.dumps(tool_use['input'], indent=2)}\")\n",
    "    \n",
    "    # Print usage stats\n",
    "    if 'usage' in response:\n",
    "        usage = response['usage']\n",
    "        print(f\"\\n[Tokens - Input: {usage['inputTokens']}, Output: {usage['outputTokens']}, Total: {usage['totalTokens']}]\")\n",
    "    \n",
    "    if 'stopReason' in response:\n",
    "        print(f\"[Stop Reason: {response['stopReason']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mistral Large 3 - Flagship Model Tests\n",
    "\n",
    "### 1.1 Basic Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"mistral.mistral-large-3-675b-instruct\"\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": \"Explain quantum computing in 3 sentences.\"}]\n",
    "}]\n",
    "\n",
    "response = converse_with_mistral(model_id, messages, max_tokens=500)\n",
    "print(\"=== Mistral Large 3 - Basic Generation ===\")\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Reasoning Use Case with Extended Thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": \"A bat and ball cost $1.10 total. The bat costs $1 more than the ball. How much does the ball cost? Think step by step.\"}]\n",
    "}]\n",
    "\n",
    "# Lower temperature for reasoning tasks\n",
    "response = converse_with_mistral(model_id, messages, max_tokens=1000, temperature=0.3)\n",
    "print(\"\\n=== Mistral Large 3 - Reasoning ===\")\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Tool Use / Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define tools using Converse API format\n",
    "tools = [{\n",
    "    \"toolSpec\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get current weather for a location\",\n",
    "        \"inputSchema\": {\n",
    "            \"json\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"City name\"\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": \"What's the weather in Paris and Tokyo?\"}]\n",
    "}]\n",
    "\n",
    "response = converse_with_mistral(model_id, messages, tools=tools)\n",
    "print(\"\\n=== Mistral Large 3 - Tool Use ===\")\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Multi-turn Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": \"What are the three laws of robotics?\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\"text\": \"The Three Laws of Robotics by Isaac Asimov are: 1) A robot may not injure a human or allow harm through inaction, 2) A robot must obey human orders unless conflicting with First Law, 3) A robot must protect itself unless conflicting with First or Second Law.\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": \"Give me a scenario where these laws conflict.\"}]\n",
    "    }\n",
    "]\n",
    "\n",
    "response = converse_with_mistral(model_id, messages)\n",
    "print(\"\\n=== Mistral Large 3 - Multi-turn ===\")\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Vision - Image Understanding\n",
    "\n",
    "Mistral Large 3 supports multimodal input with Converse API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image from local repo\n",
    "with open('Battle.png', 'rb') as f:\n",
    "    image_data = f.read()\n",
    "\n",
    "# Converse API format: use raw bytes, not base64\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"image\": {\n",
    "                \"format\": \"png\",\n",
    "                \"source\": {\"bytes\": image_data}\n",
    "            }\n",
    "        },\n",
    "        {\"text\": \"What is in this image? Describe it in detail.\"}\n",
    "    ]\n",
    "}]\n",
    "\n",
    "response = converse_with_mistral(model_id, messages, max_tokens=1000)\n",
    "print(\"\\n=== Mistral Large 3 - Vision (Converse API) ===\")\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 With System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful AI assistant that provides concise, accurate answers. Always cite sources when possible.\"\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": \"What is the speed of light?\"}]\n",
    "}]\n",
    "\n",
    "response = converse_with_mistral(model_id, messages, system=system_prompt)\n",
    "print(\"\\n=== Mistral Large 3 - With System Prompt ===\")\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ministral 3B - Efficient Small Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_id = \"mistral.ministral-3-3b-instruct\"\n",
    "\n",
    "# Code generation\n",
    "messages = [{\"role\": \"user\", \"content\": [{\"text\": \"Write a Python function to calculate fibonacci numbers.\"}]}]\n",
    "response = converse_with_mistral(model_id, messages, max_tokens=500)\n",
    "print(\"=== Ministral 3B - Code Generation ===\")\n",
    "print_response(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Tool use test\n",
    "tools = [{\n",
    "    \"toolSpec\": {\n",
    "        \"name\": \"calculate\",\n",
    "        \"description\": \"Perform mathematical calculation\",\n",
    "        \"inputSchema\": {\n",
    "            \"json\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"expression\": {\"type\": \"string\", \"description\": \"Math expression\"}\n",
    "                },\n",
    "                \"required\": [\"expression\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": [{\"text\": \"What is 234 * 567?\"}]}]\n",
    "response = converse_with_mistral(model_id, messages, tools=tools)\n",
    "print(\"\\n=== Ministral 3B - Tool Use ===\")\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load image from local repo\n",
    "with open('Battle.png', 'rb') as f:\n",
    "    image_data = f.read()\n",
    "\n",
    "# Converse API format: use raw bytes, not base64\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"image\": {\n",
    "                \"format\": \"png\",\n",
    "                \"source\": {\"bytes\": image_data}\n",
    "            }\n",
    "        },\n",
    "        {\"text\": \"What is in this image? Describe it in detail.\"}\n",
    "    ]\n",
    "}]\n",
    "\n",
    "response = converse_with_mistral(model_id, messages, max_tokens=1000)\n",
    "print(\"\\n=== Ministral 3B - Vision (Converse API) ===\")\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ministral 8B - Mid-Size Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"mistral.ministral-3-8b-instruct\"\n",
    "\n",
    "# Text analysis task\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": \"Analyze the sentiment and extract key entities from: 'Apple Inc. released iPhone 15 in September 2023, receiving positive reviews from tech enthusiasts.'\"}]\n",
    "}]\n",
    "\n",
    "response = converse_with_mistral(model_id, messages)\n",
    "print(\"=== Ministral 8B - NLP Task ===\")\n",
    "print_response(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Multi-tool use\n",
    "tools = [\n",
    "    {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"search_database\",\n",
    "            \"description\": \"Search customer database\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"required\": [\"query\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"send_email\",\n",
    "            \"description\": \"Send email to customer\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"to\": {\"type\": \"string\"},\n",
    "                        \"subject\": {\"type\": \"string\"},\n",
    "                        \"body\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"required\": [\"to\", \"subject\", \"body\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": [{\"text\": \"Find customer John Doe and send him a reminder email about his pending order.\"}]}]\n",
    "response = converse_with_mistral(model_id, messages, tools=tools)\n",
    "print(\"\\n=== Ministral 8B - Multi-Tool Use ===\")\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image from local repo\n",
    "with open('Battle.png', 'rb') as f:\n",
    "    image_data = f.read()\n",
    "\n",
    "# Converse API format: use raw bytes, not base64\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"image\": {\n",
    "                \"format\": \"png\",\n",
    "                \"source\": {\"bytes\": image_data}\n",
    "            }\n",
    "        },\n",
    "        {\"text\": \"What is in this image? Describe it in detail.\"}\n",
    "    ]\n",
    "}]\n",
    "\n",
    "response = converse_with_mistral(model_id, messages, max_tokens=1000)\n",
    "print(\"\\n=== Ministral 8B - Vision (Converse API) ===\")\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ministral 14B - Larger Efficient Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_id = \"mistral.ministral-3-14b-instruct\"\n",
    "\n",
    "# Complex reasoning task\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": \"Design a database schema for an e-commerce platform with users, products, orders, and reviews. Explain your design choices.\"}]\n",
    "}]\n",
    "\n",
    "response = converse_with_mistral(model_id, messages, max_tokens=1500)\n",
    "print(\"=== Ministral 14B - Complex Task ===\")\n",
    "print_response(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load image from local repo\n",
    "with open('Battle.png', 'rb') as f:\n",
    "    image_data = f.read()\n",
    "\n",
    "system_prompt = \"Analyze images carefully and reason step by step using [THINK] tags.\"\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"image\": {\n",
    "                \"format\": \"png\",\n",
    "                \"source\": {\"bytes\": image_data}\n",
    "            }\n",
    "        },\n",
    "        {\"text\": \"Analyze this image. What do you observe?\"}\n",
    "    ]\n",
    "}]\n",
    "\n",
    "response = converse_with_mistral(model_id, messages, system=system_prompt, max_tokens=2048)\n",
    "print(\"\\n=== Ministral 14B - (Converse API) ===\")\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Voxtral Models - Audio Transcription\n",
    "\n",
    "âœ… **Voxtral audio models WORK with proper audio format!**\n",
    "\n",
    "**Required audio format:**\n",
    "- Mono channel (1 channel)\n",
    "- 16kHz sample rate\n",
    "- MP3 format with low bitrate (32k)\n",
    "\n",
    "**Note:** For Voxtral with Converse API, we still use the invoke_model approach since Converse API has limited audio support. The audio conversion helper works for both APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_audio_for_voxtral(audio_file_or_bytes):\n",
    "    \"\"\"Convert audio to Voxtral-compatible format: mono, 16kHz, MP3\"\"\"\n",
    "    from pydub import AudioSegment\n",
    "    import io\n",
    "    \n",
    "    # Load audio (handles MP3, WAV, OGG, etc.)\n",
    "    if isinstance(audio_file_or_bytes, bytes):\n",
    "        audio = AudioSegment.from_file(io.BytesIO(audio_file_or_bytes))\n",
    "    else:\n",
    "        # Detect format from file extension\n",
    "        if audio_file_or_bytes.endswith('.mp3'):\n",
    "            audio = AudioSegment.from_mp3(audio_file_or_bytes)\n",
    "        elif audio_file_or_bytes.endswith('.ogg'):\n",
    "            audio = AudioSegment.from_ogg(audio_file_or_bytes)\n",
    "        elif audio_file_or_bytes.endswith('.wav'):\n",
    "            audio = AudioSegment.from_wav(audio_file_or_bytes)\n",
    "        else:\n",
    "            audio = AudioSegment.from_file(audio_file_or_bytes)\n",
    "    \n",
    "    # Convert to mono (1 channel)\n",
    "    audio_mono = audio.set_channels(1)\n",
    "    \n",
    "    # Convert to 16kHz sample rate\n",
    "    audio_mono = audio_mono.set_frame_rate(16000)\n",
    "    \n",
    "    # Export to MP3 bytes with low bitrate\n",
    "    mp3_io = io.BytesIO()\n",
    "    audio_mono.export(mp3_io, format='mp3', bitrate='32k')\n",
    "    \n",
    "    return mp3_io.getvalue()\n",
    "\n",
    "\n",
    "def invoke_voxtral(model_id, audio_data, prompt=\"\", max_tokens=2048):\n",
    "    \"\"\"Invoke Voxtral models with audio - uses invoke_model since Converse API has limited audio support\"\"\"\n",
    "    # Encode audio to base64\n",
    "    audio_base64 = base64.b64encode(audio_data).decode('utf-8')\n",
    "    \n",
    "    # Build content with audio\n",
    "    content = [{\n",
    "        \"type\": \"input_audio\",\n",
    "        \"input_audio\": {\n",
    "            \"data\": audio_base64,\n",
    "            \"format\": \"mp3\"\n",
    "        }\n",
    "    }]\n",
    "    \n",
    "    # Add text prompt if provided\n",
    "    if prompt:\n",
    "        content.append({\n",
    "            \"type\": \"text\",\n",
    "            \"text\": prompt\n",
    "        })\n",
    "    \n",
    "    body = {\n",
    "        \"messages\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": content\n",
    "        }],\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "    \n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body=json.dumps(body)\n",
    "    )\n",
    "    return json.loads(response['body'].read())\n",
    "\n",
    "\n",
    "# Example usage\n",
    "print(\"=== Voxtral Mini - Audio Transcription ===\")\n",
    "print(\"# Convert and transcribe audio\")\n",
    "print(\"# audio_data = convert_audio_for_voxtral('obama.mp3')\")\n",
    "print(\"# response = invoke_voxtral('mistral.voxtral-mini-3b-2507', audio_data, prompt='Summarize this audio')\")\n",
    "print(\"# print(response['choices'][0]['message']['content'])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_voxtral_converse(model_id, audio_data, prompt=\"\", max_tokens=2048):\n",
    "  \"\"\"\n",
    "  Attempt to use Converse API with audio\n",
    "  WARNING: May not work - Converse API has limited audio support for Voxtral\n",
    "  \"\"\"\n",
    "  # Build content with audio as document\n",
    "  content = [{\n",
    "          \"audio\": {\n",
    "              \"format\": \"mp3\",\n",
    "              \"source\": {\n",
    "                  \"bytes\": audio_data  # Raw bytes\n",
    "              }\n",
    "          }\n",
    "      }]\n",
    "\n",
    "  # Add text prompt if provided\n",
    "  if prompt:\n",
    "      content.append({\n",
    "          \"text\": prompt\n",
    "      })\n",
    "\n",
    "  response = bedrock_runtime.converse(\n",
    "      modelId=model_id,\n",
    "      messages=[{\n",
    "          \"role\": \"user\",\n",
    "          \"content\": content\n",
    "      }],\n",
    "      inferenceConfig={\n",
    "          \"maxTokens\": max_tokens\n",
    "      }\n",
    "  )\n",
    "\n",
    "  return response\n",
    "\n",
    "# Usage\n",
    "audio_data = convert_audio_for_voxtral('obama.mp3')\n",
    "response = invoke_voxtral_converse('mistral.voxtral-small-24b-2507', audio_data, prompt='Transcribe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['output']['message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Magistral Small 1.2 - Advanced Reasoning Model\n",
    "\n",
    "### 6.1 Advanced Reasoning with THINK Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"mistral.magistral-small-2509\"\n",
    "\n",
    "# system_prompt = \"You are a helpful assistant that thinks step by step. Use [THINK] and [/THINK] tokens to show your reasoning process before providing the final answer.\"\n",
    "\n",
    "system_prompt = \"\"\"First draft your thinking process (inner monologue) until you arrive at a response. \n",
    "Format your response using Markdown, and use LaTeX for any mathematical equations. \n",
    "Write both your thoughts and the response in the same language as the input.\n",
    "\n",
    "Your thinking process must follow the template below:[THINK]Your thoughts or/and draft, \n",
    "like working through an exercise on scratch paper. Be as casual and as long as you want until you are confident to generate the response. \n",
    "Use the same language as the input.[/THINK]Here, provide a self-contained response.\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": \"A farmer has 17 sheep, and all but 9 die. How many sheep are left?\"}]\n",
    "}]\n",
    "\n",
    "response = converse_with_mistral(model_id, messages, system=system_prompt, max_tokens=2048, temperature=0.7)\n",
    "print(\"=== Magistral Small - Basic Reasoning ===\")\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Image analysis with Converse API\n",
    "with open('Battle.png', 'rb') as f:\n",
    "    image_data = f.read()\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"image\": {\n",
    "                \"format\": \"png\",\n",
    "                \"source\": {\"bytes\": image_data}\n",
    "            }\n",
    "        },\n",
    "        {\"text\": \"What action do you think I should take in this situation? List all the possible actions and explain why you think they are good or bad.\"}\n",
    "    ]\n",
    "}]\n",
    "\n",
    "response = converse_with_mistral(\n",
    "    model_id='mistral.magistral-small-2509',\n",
    "    messages=messages,\n",
    "    max_tokens=2048,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95\n",
    ")\n",
    "print(\"\\n=== Magistral Small - Document Analysis (Converse API) ===\")\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converse API Benefits\n",
    "\n",
    "Key advantages of using the Converse API:\n",
    "\n",
    "1. **Unified Interface**: Consistent API across all models\n",
    "2. **Built-in Token Tracking**: Automatic usage statistics (inputTokens, outputTokens, totalTokens)\n",
    "3. **System Prompts**: Dedicated parameter for system instructions\n",
    "4. **Inference Config**: Centralized parameter management (maxTokens, temperature, topP)\n",
    "5. **Tool Configuration**: Standardized tool/function calling with toolChoice options\n",
    "6. **Stop Reason**: Explicit indication of why generation stopped\n",
    "7. **Multi-modal Support**: Native support for text and images in content array\n",
    "8. **Simplified Error Handling**: Consistent response structure\n",
    "\n",
    "## Summary\n",
    "\n",
    "**Text Models Tested:**\n",
    "- **Mistral Large 3**: Complex reasoning, multi-turn conversations, tool use, system prompts\n",
    "- **Ministral 3B/8B/14B**: Efficient models with tool use and varying capabilities\n",
    "- **Magistral Small 1.2**: Advanced reasoning with [THINK] tokens, vision, optimized configs\n",
    "\n",
    "**Audio Models:**\n",
    "- **Voxtral Mini/Small**\n",
    "\n",
    "**Key Capabilities Tested:**\n",
    "- Text generation with inferenceConfig\n",
    "- System prompts for context and instructions\n",
    "- Tool use with toolSpec format\n",
    "- Multi-turn conversations\n",
    "- Vision reasoning (images + text)\n",
    "- Reasoning with [THINK] tokens\n",
    "- Performance benchmarking with token tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
