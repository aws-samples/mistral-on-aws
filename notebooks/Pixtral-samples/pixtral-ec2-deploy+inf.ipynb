{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fbabc6c-70df-4916-a861-970f51c17cd3",
   "metadata": {},
   "source": [
    "# Containerized Deployment and Inference with Pixtral on EC2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617d14b6-d489-4116-9a84-885f84dc21ff",
   "metadata": {},
   "source": [
    "In this notebook we will be deploying [Mistral's Pixtral model](https://huggingface.co/mistralai/Pixtral-12B-2409) as a containerized inference server on Amazon EC2. Pixtral is trained to understand both natural images and documents, achieving 52.5% on the MMMU reasoning benchmark, surpassing a number of larger models. The model shows strong abilities in tasks such as chart and figure understanding, document question answering, multimodal reasoning and instruction following. Pixtral is able to ingest images at their natural resolution and aspect ratio, giving the user flexibility on the number of tokens used to process an image. Pixtral is also able to process any number of images in its long context window of 128K tokens. Unlike previous open-source models, Pixtral does not compromise on text benchmark performance to excel in multimodal tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200245ff-f2ed-4995-82a6-b68aef9ea6c2",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Follow the steps below to set up your EC2 instance with the Ubuntu DLAMI that comes pre-installed with Nvidia drivers, docker, and other tools that you will require.\n",
    "\n",
    "#### Create Your EC2 instance\n",
    "##### Follow the steps here for a detailed set up of your EC2 instance: [setup](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EC2_GetStarted.html)\n",
    "\n",
    "##### Steps:\n",
    "- Navigate to the EC2 dashboard from the AWS mgmt console and launch your instance.\n",
    "- Search for the `Deep Learning Base OSS Nvidia driver GPU AMI (Ubuntu 22.04)` and select it.\n",
    "-  Choose the instance size as `g5.12xlarge` or any larger instance size.\n",
    "> [!NOTE]  \n",
    "> Depending on the instance size, you will need to adjust the `tensor_parallel_size` parameter and the `max_model_len` as with the g5.12xlarge the max KV cache is smaller than the max model context length of 128k tokens. Feel free to not specify the `max_model_len` with larger instance sizes to fully utilize the context window.\n",
    "- Set the inbound rule for `ssh` to your local machine's ip address or `anywhere` (note that it is not in accordance to set this to allow trafic from any ipv4, please ensure you secure these ports once done testing.\n",
    "- Create and specify your ssh key in the instance configuration step. You will need your `.pem` file\n",
    "- Set the EBS volume sie to 100GB `gp3`.\n",
    "- Create your instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ffe025-4139-45a4-b826-1eeaff5cc049",
   "metadata": {},
   "source": [
    "Once you have launched your instance, navigate to either your terminal or VSCODE and follow the steps below:\n",
    "\n",
    "ssh for powershell:\n",
    "```\n",
    "$PUBLIC_DNS=\"paste your public ipv4 dns here\" # public ipv4 DNS, e.g. ec2-3-80-.... from ec2 console\n",
    "$KEY_PATH=\"paste ssh key path here\" # local path to key, e.g. ssh/trn.pem\n",
    "\n",
    "ssh -i $KEY_PATH -L 8080:localhost:8080 ubuntu@$PUBLIC_DNS\n",
    "```\n",
    "ssh for linux/macOS\n",
    "```\n",
    "export PUBLIC_DNS=\"paste your public ipv4 dns here\" # public ipv4 DNS, e.g. ec2-3-80-.... from ec2 console\n",
    "export KEY_PATH=\"paste ssh key path here\" # local path to key, e.g. ssh/trn.pem\n",
    "\n",
    "ssh -i $KEY_PATH -L 8080:localhost:8080 ubuntu@$PUBLIC_DNS\n",
    "``` \n",
    "\n",
    "You should have sshed into your EC2 instance.\n",
    "Next we can change our directory to home, create a directory for our notebook, install jupyter, and launch the jupyter environment.\n",
    "```\n",
    "ubuntu@ip-172-31-0-170:~$ cd\n",
    "ubuntu@ip-172-31-0-170:~$ cd jupyter-pixtral/\n",
    "ubuntu@ip-172-31-0-170:~/jupyter-pixtral$ cd notebooks/\n",
    "ubuntu@ip-172-31-0-170:~/jupyter-pixtral/notebooks$ sudo pip3 install notebook\n",
    "ubuntu@ip-172-31-0-170:~/jupyter-pixtral/notebooks$ python3 -m notebook --allow-root --port=8080 \n",
    "```\n",
    "You should see a familiar jupyter output with a URL to the notebook.\n",
    "\n",
    "`http://localhost:8080/....`\n",
    "\n",
    "We can click on it, and a jupyter environment opens in our local browser. Upload this notebook to your jupyter environment and runthe steps in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c83068a-c2b1-4d2e-8c16-a5e3917edd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: docker: Error response from daemon: driver failed programming external connectivity on endpoint stoic_lamport (ed88c7cdf65725e099388e97fe4c6b1fc8e92b89bdfac66499021cd18bc8b995): Bind for 0.0.0.0:8000 failed: port is already allocated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the bash script\n",
    "bash_script = \"\"\"\n",
    "export HF_TOKEN=\"provide your hf token\"\n",
    "\n",
    "docker run --runtime nvidia --gpus all \\\n",
    "    -v ~/.cache/huggingface:/root/.cache/huggingface \\\n",
    "    --env HUGGING_FACE_HUB_TOKEN=${HF_TOKEN} \\\n",
    "    -p 8000:8000 \\\n",
    "    --ipc=host \\\n",
    "    vllm/vllm-openai:v0.6.1.post2 \\\n",
    "    --model mistralai/Pixtral-12B-2409 \\\n",
    "    --tokenizer_mode mistral \\\n",
    "    --load_format mistral \\\n",
    "    --config_format mistral \\\n",
    "    --tensor_parallel_size 4 \\\n",
    "    --gpu_memory_utilization 0.9 \\\n",
    "    --max_model_len 60000\n",
    "\"\"\"\n",
    "# Run the bash script and capture real-time output\n",
    "process = subprocess.Popen(bash_script, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "while True:\n",
    "    output = process.stdout.readline()\n",
    "    if output == b'' and process.poll() is not None:\n",
    "        break\n",
    "    if output:\n",
    "        print(output.decode().strip())\n",
    "\n",
    "# Capture and print any errors\n",
    "stderr = process.stderr.read().decode()\n",
    "if stderr:\n",
    "    print(\"Errors:\", stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb4a466f-d7bc-4a97-b42c-30fc38c07a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: devscripts 2.22.1ubuntu1 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of devscripts or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mDEPRECATION: devscripts 2.22.1ubuntu1 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of devscripts or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mDEPRECATION: devscripts 2.22.1ubuntu1 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of devscripts or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script jupyter-console is installed in '/home/ubuntu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade requests --quiet\n",
    "!pip install --upgrade gradio --quiet\n",
    "!pip install --upgrade jupyter ipywidgets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43031467-aa9e-4d6e-9efd-a6e7638c9abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chat-62d19c41603f4796b3f10d3e15677d67', 'object': 'chat.completion', 'created': 1727113071, 'model': 'mistralai/Pixtral-12B-2409', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'The image depicts a coastal town at sunset, characterized by its white buildings with flat roofs and some blue accents on the shutters. The town is situated along the seafront, with a prominent pier extending into the calm waters. The sky transitions from light hues near the horizon to deeper blue above, indicating the setting sun. The overall ambiance is serene and picturesque, typical of a Mediterranean or Greek island setting. The architecture, combined with the location and atmosphere, suggests that this could be Mykonos, a popular Greek island known for its white-washed buildings and picturesque sunsets.', 'tool_calls': []}, 'logprobs': None, 'finish_reason': 'stop', 'stop_reason': None}], 'usage': {'prompt_tokens': 2701, 'total_tokens': 2823, 'completion_tokens': 122}, 'prompt_logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "  import httpx\n",
    "\n",
    "  url = \"http://localhost:8000/v1/chat/completions\"\n",
    "  headers = {\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer token\"}\n",
    "  timeout=httpx.Timeout(250.0) #increase timeout as needed\n",
    "  data = {\n",
    "      \"model\": \"mistralai/Pixtral-12B-2409\",\n",
    "      \"messages\": [\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": [\n",
    "                  {\"type\": \"text\", \"text\": \"Describe and identify the location in this image.\"},\n",
    "                  {\n",
    "                      \"type\": \"image_url\",\n",
    "                      \"image_url\": {\"url\": \"https://huggingface.co/datasets/nithiyn/bounding-box/resolve/main/mykonos-2.jpeg\"},\n",
    "                  },\n",
    "              ],\n",
    "          }\n",
    "      ],\n",
    "  }\n",
    "\n",
    "  response = httpx.post(url, headers=headers, json=data)\n",
    "\n",
    "  print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7623c32c-672d-4045-922c-1e0ad8a55d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image depicts a coastal town at sunset, characterized by its white buildings with flat roofs and some blue accents on the shutters. The town is situated along the seafront, with a prominent pier extending into the calm waters. The sky transitions from light hues near the horizon to deeper blue above, indicating the setting sun. The overall ambiance is serene and picturesque, typical of a Mediterranean or Greek island setting. The architecture, combined with the location and atmosphere, suggests that this could be Mykonos, a popular Greek island known for its white-washed buildings and picturesque sunsets.\n"
     ]
    }
   ],
   "source": [
    "response_json= response.json()\n",
    "print(response_json['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cfbdda1-585d-4156-a063-5ff43ffa1659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "Running on public URL: https://01f633a521e020e4f5.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://01f633a521e020e4f5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import httpx\n",
    "\n",
    "# Function that sends the input to the API and returns the response\n",
    "def call_api(text_prompt, image_urls):\n",
    "    url = \"http://localhost:8000/v1/chat/completions\"\n",
    "    headers = {\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer token\"}\n",
    "    timeout=httpx.Timeout(250.0) #increase timeout as needed\n",
    "    # Create the list of image content messages\n",
    "    content_list = [{\"type\": \"text\", \"text\": text_prompt}]\n",
    "    \n",
    "    # Add each image URL as a message with its type\n",
    "    for image_url in image_urls:\n",
    "        content_list.append({\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": image_url}\n",
    "        })\n",
    "    \n",
    "    # Construct the request payload\n",
    "    data = {\n",
    "        \"model\": \"mistralai/Pixtral-12B-2409\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content_list,  # Pass the list of text and image URLs\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    # Send the request to the API\n",
    "    response = httpx.post(url, headers=headers, json=data)\n",
    "\n",
    "    # Return the API response (assuming the response is in JSON format)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n",
    "\n",
    "# Define Gradio interface\n",
    "def gradio_interface():\n",
    "    # Inputs: Textbox for prompt and Textbox for multiple image URLs\n",
    "    text_prompt = gr.Textbox(label=\"Enter text prompt\", placeholder=\"Describe and identify the location in these images.\")\n",
    "    \n",
    "    # Add a new input for multiple URLs using Textbox and set it as a list\n",
    "    image_urls = gr.Textbox(label=\"Enter image URLs (comma separated)\", placeholder=\"Enter your URL\")\n",
    "    \n",
    "    # Output: The generated content from the model\n",
    "    output_text = gr.Textbox(label=\"Generated Description\")\n",
    "\n",
    "    # Create the Gradio interface\n",
    "    interface = gr.Interface(\n",
    "        fn=lambda text, urls: call_api(text, urls.split(',')),  # Split URLs by comma and pass them as a list\n",
    "        inputs=[text_prompt, image_urls],  # Inputs to the function\n",
    "        outputs=output_text,   # Output returned by the function\n",
    "        title=\"Multi-Image Description Generator\",  # Title for the interface\n",
    "        description=\"Enter a text prompt and multiple image URLs, and the model will describe the images and their locations.\"\n",
    "    )\n",
    "    \n",
    "    # Launch the interface\n",
    "    interface.launch(share=True)\n",
    "\n",
    "# Run the Gradio interface\n",
    "if __name__ == \"__main__\":\n",
    "    gradio_interface()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe8d43-4e1a-431e-b871-01a9b08d6977",
   "metadata": {},
   "source": [
    "---\n",
    "### Distributors\n",
    "- AWS\n",
    "- Mistral"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
