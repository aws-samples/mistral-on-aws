{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c70d750-8e48-49e6-a44b-37ef1f44dc79",
   "metadata": {},
   "source": [
    "# Preparing Mistral NeMo for Amazon Bedrock Custom Model Import (CMI)\n",
    "\n",
    "This notebook demonstrates how to prepare and import Mistral NeMo into Amazon Bedrock using Custom Model Import (CMI).\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **HuggingFace Access**\n",
    "   - Active HuggingFace account\n",
    "   - Valid access token\n",
    "   - CLI authentication with HuggingFace (required for file transfers)\n",
    "\n",
    "2. **File Transfer Method**\n",
    "   - This notebook uses HF Transfer for efficient direct transfers from HuggingFace\n",
    "   - Alternative: Manual download and S3 upload\n",
    "\n",
    "3. **Model Configuration Requirements**\n",
    "   - Must set `max_position_embeddings` to 8192 or less to comply with Bedrock limits\n",
    "   - Defines the maximum sequence length\n",
    "\n",
    "4. **File Format Requirements**\n",
    "   - All model files must be in HuggingFace format\n",
    "   - Required files include:\n",
    "     - Model weights (.safetensors)\n",
    "     - Configuration files (config.json, generation_config.json)\n",
    "     - Tokenizer files (tokenizer.json, tokenizer_config.json)\n",
    "     - Supporting files (vocab.json, merges.txt, special_tokens_map.json)\n",
    "5. **EBS Volume**\n",
    "   - If the notebook is run from Sagemaker Notebook instance, increase the EBS volume to 100gb\n",
    "\n",
    "## Important Note on Model Precision\n",
    "Bedrock CMI has specific requirements for model precision:\n",
    "- Supported: FP32, FP16, and BF16 precision\n",
    "- Not supported: Quantized models (including 4-bit quantization)\n",
    "- Note: FP32 models will be automatically converted to BF16 precision internally by Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4374d2dd-5f28-4b8e-a6e3-c6f70650c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers hf_transfer huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7957bf-3cfb-427b-8174-ed9e990d7287",
   "metadata": {},
   "source": [
    "## Create IAM role and policy for CMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acbb5c1-23a2-455b-ab11-ca80df1bc2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "iam.create_role(\n",
    "    RoleName=\"MyImportModelRole\",\n",
    "    AssumeRolePolicyDocument=json.dumps({\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"Service\": \"bedrock.amazonaws.com\"\n",
    "                },\n",
    "                \"Action\": \"sts:AssumeRole\"\n",
    "            }\n",
    "        ] \n",
    "    })\n",
    ")\n",
    "\n",
    "iam.create_policy(\n",
    "    PolicyName=\"S3BucketPolicy\",\n",
    "    PolicyDocument=json.dumps({\n",
    "    \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\",\n",
    "                \"s3:DeleteObject\"\n",
    "                ],\n",
    "            \"Resource\": [\n",
    "            \"arn:aws:s3:::{YOUR_S3_BUCKET}\",\n",
    "            \"arn:aws:s3:::{YOUR_S3_BUCKET}/*\"\n",
    "            ]\n",
    "            }\n",
    "        ]\n",
    "}\n",
    ")\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ef5551",
   "metadata": {},
   "source": [
    "## Attach Policy to the Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7174c93d-9138-4324-a297-ddcca1a49992",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam.attach_role_policy(\n",
    "    RoleName=\"MyImportModelRole\",\n",
    "    PolicyArn=\"YOUR_POLICY_ARN\" #the previous cell will display the ARN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f24354-6bc6-49f8-8f35-19d736608558",
   "metadata": {},
   "source": [
    "## Download and Upload Hugging Face Model Files to S3 using HF Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69ea144-0cac-4c84-867a-ef4d03b0e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from huggingface_hub import hf_hub_download, login, snapshot_download\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "HF_TOKEN = \"YOUR_HF_TOKEN\"\n",
    "login(token = HF_TOKEN)\n",
    "\n",
    "# Enable the faster transfers\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
    "\n",
    "# Repository and files\n",
    "repo_id = \"mistralai/Mistral-Nemo-Instruct-2407\"\n",
    "\n",
    "# S3 configuration\n",
    "bucket_name = \"YOUR_BUCKET_NAME\"\n",
    "prefix = \"YOUR_PREFIX\"\n",
    "\n",
    "# Download location\n",
    "temp_dir = \"./temp_model_files\"\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "snapshot_path = snapshot_download(\n",
    "    repo_id=\"mistralai/Mistral-Nemo-Instruct-2407\",\n",
    "    local_dir=temp_dir,\n",
    "    ignore_patterns=[\"consolidated.safetensors\"]\n",
    ")\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(snapshot_path):\n",
    "    for file in files:\n",
    "        local_file_path = os.path.join(root, file)\n",
    "        # Compute S3 key to preserve relative path\n",
    "        rel_path = os.path.relpath(local_file_path, snapshot_path)\n",
    "        s3_key = os.path.join(prefix, rel_path)\n",
    "        print(f\"Uploading {local_file_path} to s3://{bucket_name}/{s3_key}...\")\n",
    "        try:\n",
    "            s3_client.upload_file(\n",
    "                Filename=local_file_path,\n",
    "                Bucket=bucket_name,\n",
    "                Key=s3_key\n",
    "            )\n",
    "            print(f\"Successfully uploaded {rel_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading {rel_path}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af116cab-5239-4434-b099-4a9a2f72c7ee",
   "metadata": {},
   "source": [
    "## Update max_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738718dd-23df-440f-bc35-292d5c504c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# S3 details\n",
    "bucket_name = 'YOUR_BUCKET_NAME'\n",
    "config_key = '{PREFIX}/config.json'  # full path to config.json\n",
    "\n",
    "# Download the current config\n",
    "response = s3.get_object(Bucket=bucket_name, Key=config_key)\n",
    "config = json.loads(response['Body'].read().decode('utf-8'))\n",
    "\n",
    "# Modify the config\n",
    "config['max_position_embeddings'] = 8192  # Using Bedrock's recommended value\n",
    "\n",
    "# Upload modified config back to S3\n",
    "s3.put_object(\n",
    "    Bucket=bucket_name,\n",
    "    Key=config_key,\n",
    "    Body=json.dumps(config, indent=2),\n",
    "    ContentType='application/json'\n",
    ")\n",
    "\n",
    "print(\"Config updated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356b1461-0f76-410d-98df-ac90d79c797f",
   "metadata": {},
   "source": [
    "## Start CMI Import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbb4d54-008f-434d-b652-0558c6bb67f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Initialize Bedrock client\n",
    "bedrock = boto3.client('bedrock')\n",
    "\n",
    "def start_model_import(\n",
    "    bucket_name=\"YOUR_BUCKET_NAME\", \n",
    "    prefix=\"PREFIX\",\n",
    "    model_name=\"mistral-nemo-test\",\n",
    "    role_arn=\"YOUR_ROLE_ARN\" \n",
    "):\n",
    "    \n",
    "    # Construct S3 URI\n",
    "    s3_uri = f\"s3://{bucket_name}/{prefix}\"\n",
    "    \n",
    "    try:\n",
    "        response = bedrock.create_model_import_job(\n",
    "            importedModelName=model_name,\n",
    "            jobName=f\"{model_name}-import-{int(time.time())}\",\n",
    "            modelDataSource={\n",
    "                \"s3DataSource\": {\n",
    "                    \"s3Uri\": s3_uri\n",
    "                }\n",
    "            },\n",
    "            roleArn=role_arn\n",
    "        )\n",
    "        \n",
    "        print(f\"Model import job created successfully. Job ARN: {response['jobArn']}\")\n",
    "        return response['jobArn']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating model import job: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def check_import_status(job_arn):\n",
    "    try:\n",
    "        response = bedrock.get_model_import_job(\n",
    "            jobIdentifier=job_arn\n",
    "        )\n",
    "        # Print full response for debugging\n",
    "        print(\"Full response:\")\n",
    "        print(json.dumps(response, indent=2, default=str))\n",
    "        \n",
    "        # Try to get status from response\n",
    "        if 'status' in response:\n",
    "            return response['status']\n",
    "        elif 'modelImportJob' in response and 'status' in response['modelImportJob']:\n",
    "            return response['modelImportJob']['status']\n",
    "        else:\n",
    "            print(\"Status not found in response structure\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error checking job status: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Start the import\n",
    "job_arn = start_model_import()\n",
    "\n",
    "# Monitor the import status\n",
    "while True:\n",
    "    try:\n",
    "        status = check_import_status(job_arn)\n",
    "        if status:\n",
    "            print(f\"Import status: {status}\")\n",
    "            if status in ['Completed', 'Failed']:\n",
    "                break\n",
    "        else:\n",
    "            print(\"Could not determine status\")\n",
    "            break\n",
    "        time.sleep(60)  # Check every minute\n",
    "    except Exception as e:\n",
    "        print(f\"Error in monitoring loop: {str(e)}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d577e008-c236-4764-b93a-c9bbb0dd2a89",
   "metadata": {},
   "source": [
    "## Test Inference with Imported Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7277a5b7-ae0f-49f5-9066-c89272580e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Bedrock Runtime client\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name='us-west-2'\n",
    ")\n",
    "\n",
    "# Test prompt\n",
    "prompt = \"What does Mistral AI do?\"\n",
    "\n",
    "# Prepare the request body\n",
    "request_body = {\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": 500,\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_k\": 50\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Invoke the model\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        modelId='YOUR_MODEL_ARN', #from the bedrock console under imported models\n",
    "        body=json.dumps(request_body)\n",
    "    )\n",
    "    \n",
    "    # Parse and print the response\n",
    "    response_body = json.loads(response['body'].read())\n",
    "    print(\"Response:\")\n",
    "    print(response_body)\n",
    "    text_content = response_body['outputs'][0]['text']\n",
    "    print(\"Response text:\\n\", text_content)\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e56e1",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "The following resources were created and may need cleanup:\n",
    "\n",
    "- Local temporary files in `./temp_model_files`\n",
    "- S3 objects (model files uploaded to your bucket)\n",
    "- IAM role \"MyImportModelRole\"\n",
    "- IAM policy \"S3BucketPolicy\"\n",
    "- Imported Bedrock model (optional cleanup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d84c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleanup Resources\n",
    "\n",
    "import boto3\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Initialize clients\n",
    "bedrock = boto3.client('bedrock')\n",
    "s3 = boto3.client('s3')\n",
    "iam = boto3.client('iam')\n",
    "\n",
    "# Set your variables (same as used earlier)\n",
    "bucket_name = \"YOUR_BUCKET_NAME\"\n",
    "prefix = \"PREFIX\"\n",
    "model_name = \"mistral-nemo-test\"  # The name you used for the imported model\n",
    "policy_name = \"S3BucketPolicy\"\n",
    "role_name = \"MyImportModelRole\"\n",
    "policy_arn = \"YOUR_POLICY_ARN\"  # The ARN of the policy you created\n",
    "\n",
    "# 1. Delete local temporary files\n",
    "print(\"Cleaning up local temporary files...\")\n",
    "if os.path.exists(\"./temp_model_files\"):\n",
    "    shutil.rmtree(\"./temp_model_files\")\n",
    "    print(\"✓ Local temporary files deleted\")\n",
    "else:\n",
    "    print(\"No local temporary files found\")\n",
    "\n",
    "# 2. Delete S3 objects\n",
    "print(f\"\\nCleaning up S3 objects in s3://{bucket_name}/{prefix}/...\")\n",
    "try:\n",
    "    # List all objects with the prefix\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "    \n",
    "    if 'Contents' in response:\n",
    "        # Create a list of objects to delete\n",
    "        objects_to_delete = [{'Key': obj['Key']} for obj in response['Contents']]\n",
    "        \n",
    "        # Delete the objects\n",
    "        s3.delete_objects(\n",
    "            Bucket=bucket_name,\n",
    "            Delete={'Objects': objects_to_delete}\n",
    "        )\n",
    "        print(f\"✓ Deleted {len(objects_to_delete)} objects from S3\")\n",
    "    else:\n",
    "        print(\"No objects found in the specified S3 prefix\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error deleting S3 objects: {str(e)}\")\n",
    "\n",
    "# 3. Optional: Delete the imported model from Bedrock\n",
    "# CAUTION: Only do this if you no longer need the imported model\n",
    "delete_model = input(\"Do you want to delete the imported Bedrock model? (yes/no): \")\n",
    "if delete_model.lower() == 'yes':\n",
    "    try:\n",
    "        print(f\"\\nDeleting imported model {model_name}...\")\n",
    "        bedrock.delete_imported_model(\n",
    "            modelIdentifier=model_name  # You might need to use the full ARN instead\n",
    "        )\n",
    "        print(\"✓ Imported model deleted\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting imported model: {str(e)}\")\n",
    "        print(\"You may need to delete the model manually from the Bedrock console\")\n",
    "else:\n",
    "    print(\"\\nSkipping model deletion\")\n",
    "\n",
    "# 4. Detach and delete IAM policy\n",
    "print(\"\\nCleaning up IAM resources...\")\n",
    "try:\n",
    "    # Detach policy from role\n",
    "    iam.detach_role_policy(\n",
    "        RoleName=role_name,\n",
    "        PolicyArn=policy_arn\n",
    "    )\n",
    "    print(f\"✓ Policy {policy_name} detached from role {role_name}\")\n",
    "    \n",
    "    # Delete policy\n",
    "    iam.delete_policy(\n",
    "        PolicyArn=policy_arn\n",
    "    )\n",
    "    print(f\"✓ Policy {policy_name} deleted\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error cleaning up IAM policy: {str(e)}\")\n",
    "\n",
    "# 5. Delete IAM role\n",
    "try:\n",
    "    iam.delete_role(\n",
    "        RoleName=role_name\n",
    "    )\n",
    "    print(f\"✓ Role {role_name} deleted\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting IAM role: {str(e)}\")\n",
    "    print(\"Note: If the role has any remaining attached policies, it cannot be deleted\")\n",
    "\n",
    "print(\"\\nCleanup complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
