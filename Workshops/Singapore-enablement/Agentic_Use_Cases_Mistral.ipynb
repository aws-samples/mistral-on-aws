{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Use Cases with Mistral\n",
    "\n",
    "This notebook explores advanced agentic use cases and multi-agent workflow patterns using Mistral models on AWS. You'll learn how to build sophisticated security investigation systems that go beyond simple agent calls to create coordinated, multi-agent workflows with specialized roles and intelligent orchestration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to build intelligent security analysis systems using **Strands Agents** framework with Mistral's **Pixtral Large** model on Amazon Bedrock. \n",
    "\n",
    "### What You'll Build:\n",
    "\n",
    "#### 1. Single-Agent Security Analysis\n",
    "- Analyze CloudWatch logs for security incidents\n",
    "- Review AWS SecurityHub compliance findings\n",
    "- Detect performance anomalies in metrics data\n",
    "- Correlate events across multiple data sources\n",
    "- Provide actionable remediation recommendations\n",
    "\n",
    "#### 2. Multi-Agent Workflow Orchestration\n",
    "- **Triage Agent**: Routes investigations to appropriate specialists\n",
    "- **Log Analysis Agent**: Focuses on CloudWatch security events\n",
    "- **Compliance Agent**: Reviews SecurityHub findings\n",
    "- **Metrics Agent**: Detects performance anomalies\n",
    "- **Remediation Agent**: Synthesizes findings into action plans\n",
    "\n",
    "### Key Capabilities:\n",
    "\n",
    "- **Tool Functions**: Agents use decorated Python functions with `@tool` to query data\n",
    "- **Sequential Orchestration**: Agents build upon each other's findings\n",
    "- **Conditional Routing**: Workflow adapts based on investigation type\n",
    "- **State Management**: Track findings across multiple agent executions\n",
    "- **Synthesis**: Final agent combines insights from all specialists\n",
    "\n",
    "This notebook uses tool functions to query dummy data (CloudWatch logs, SecurityHub findings, and time-series metrics) to simulate real-world security analysis workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Single-Agent Security Analysis with Pixtral Large and Strands Agents\n",
    "\n",
    "This section demonstrates using Pixtral Large with AWS Bedrock and the **Strands Agents** framework to create a single security analysis agent that can investigate security incidents, detect anomalies, and provide actionable insights.\n",
    "\n",
    "### What You'll Learn in Part 1:\n",
    "- Creating realistic dummy data for CloudWatch logs and SecurityHub findings\n",
    "- Setting up Strands Agents with Pixtral Large (us.mistral.pixtral-large-2502-v1:0)\n",
    "- Implementing tool functions with the `@tool` decorator\n",
    "- Running single-agent security investigations\n",
    "- Tracking execution time and Bedrock API usage\n",
    "\n",
    "### What's Coming in Part 2:\n",
    "After mastering single-agent analysis, you'll learn to build **multi-agent workflows** with specialized agents, conditional routing, and orchestrated synthesis of findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Strands Agents imports\n",
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "from strands.tools import tool\n",
    "\n",
    "print(\"✅ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dummy CloudWatch Log Data\n",
    "\n",
    "We'll create realistic CloudWatch log entries with various events including failed authentications, application errors, and security incidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy CloudWatch log entries\n",
    "base_time = datetime.now() - timedelta(hours=2)\n",
    "\n",
    "cloudwatch_logs = [\n",
    "    {\n",
    "        \"timestamp\": (base_time + timedelta(minutes=5)).isoformat(),\n",
    "        \"level\": \"ERROR\",\n",
    "        \"message\": \"Failed authentication attempt for user: admin\",\n",
    "        \"source_ip\": \"185.220.101.47\",\n",
    "        \"user_agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "        \"request_id\": \"req-001\",\n",
    "        \"service\": \"auth-service\",\n",
    "        \"error_code\": \"AUTH_FAILED\",\n",
    "        \"attempt_count\": 3\n",
    "    },\n",
    "    {\n",
    "        \"timestamp\": (base_time + timedelta(minutes=6)).isoformat(),\n",
    "        \"level\": \"ERROR\",\n",
    "        \"message\": \"Failed authentication attempt for user: admin\",\n",
    "        \"source_ip\": \"185.220.101.47\",\n",
    "        \"user_agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "        \"request_id\": \"req-002\",\n",
    "        \"service\": \"auth-service\",\n",
    "        \"error_code\": \"AUTH_FAILED\",\n",
    "        \"attempt_count\": 4\n",
    "    },\n",
    "    {\n",
    "        \"timestamp\": (base_time + timedelta(minutes=7)).isoformat(),\n",
    "        \"level\": \"CRITICAL\",\n",
    "        \"message\": \"Account locked due to multiple failed authentication attempts\",\n",
    "        \"source_ip\": \"185.220.101.47\",\n",
    "        \"user_agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "        \"request_id\": \"req-003\",\n",
    "        \"service\": \"auth-service\",\n",
    "        \"error_code\": \"ACCOUNT_LOCKED\",\n",
    "        \"username\": \"admin\"\n",
    "    },\n",
    "    {\n",
    "        \"timestamp\": (base_time + timedelta(minutes=15)).isoformat(),\n",
    "        \"level\": \"ERROR\",\n",
    "        \"message\": \"Database connection timeout\",\n",
    "        \"source_ip\": \"10.0.1.45\",\n",
    "        \"user_agent\": \"Internal-Service/1.0\",\n",
    "        \"request_id\": \"req-004\",\n",
    "        \"service\": \"api-gateway\",\n",
    "        \"error_code\": \"DB_TIMEOUT\",\n",
    "        \"latency_ms\": 30000\n",
    "    },\n",
    "    {\n",
    "        \"timestamp\": (base_time + timedelta(minutes=18)).isoformat(),\n",
    "        \"level\": \"WARNING\",\n",
    "        \"message\": \"API rate limit exceeded\",\n",
    "        \"source_ip\": \"203.0.113.42\",\n",
    "        \"user_agent\": \"python-requests/2.28.0\",\n",
    "        \"request_id\": \"req-005\",\n",
    "        \"service\": \"api-gateway\",\n",
    "        \"error_code\": \"RATE_LIMIT_EXCEEDED\",\n",
    "        \"requests_count\": 1502\n",
    "    },\n",
    "    {\n",
    "        \"timestamp\": (base_time + timedelta(minutes=25)).isoformat(),\n",
    "        \"level\": \"CRITICAL\",\n",
    "        \"message\": \"SQL injection attempt detected\",\n",
    "        \"source_ip\": \"198.51.100.89\",\n",
    "        \"user_agent\": \"curl/7.68.0\",\n",
    "        \"request_id\": \"req-006\",\n",
    "        \"service\": \"api-gateway\",\n",
    "        \"error_code\": \"SECURITY_VIOLATION\",\n",
    "        \"payload\": \"SELECT * FROM users WHERE id='1' OR '1'='1'--\"\n",
    "    },\n",
    "    {\n",
    "        \"timestamp\": (base_time + timedelta(minutes=32)).isoformat(),\n",
    "        \"level\": \"ERROR\",\n",
    "        \"message\": \"S3 access denied\",\n",
    "        \"source_ip\": \"10.0.2.67\",\n",
    "        \"user_agent\": \"aws-sdk-python/1.26.0\",\n",
    "        \"request_id\": \"req-007\",\n",
    "        \"service\": \"data-processor\",\n",
    "        \"error_code\": \"S3_ACCESS_DENIED\",\n",
    "        \"bucket\": \"sensitive-data-bucket\"\n",
    "    },\n",
    "    {\n",
    "        \"timestamp\": (base_time + timedelta(minutes=45)).isoformat(),\n",
    "        \"level\": \"ERROR\",\n",
    "        \"message\": \"Failed authentication attempt for user: root\",\n",
    "        \"source_ip\": \"185.220.101.47\",\n",
    "        \"user_agent\": \"Mozilla/5.0 (X11; Linux x86_64)\",\n",
    "        \"request_id\": \"req-008\",\n",
    "        \"service\": \"auth-service\",\n",
    "        \"error_code\": \"AUTH_FAILED\",\n",
    "        \"attempt_count\": 1\n",
    "    },\n",
    "    {\n",
    "        \"timestamp\": (base_time + timedelta(minutes=50)).isoformat(),\n",
    "        \"level\": \"WARNING\",\n",
    "        \"message\": \"Unusual spike in 404 errors\",\n",
    "        \"source_ip\": \"192.0.2.156\",\n",
    "        \"user_agent\": \"Mozilla/5.0 (compatible; SomeBot/1.0)\",\n",
    "        \"request_id\": \"req-009\",\n",
    "        \"service\": \"web-frontend\",\n",
    "        \"error_code\": \"NOT_FOUND\",\n",
    "        \"error_count\": 237\n",
    "    },\n",
    "    {\n",
    "        \"timestamp\": (base_time + timedelta(minutes=60)).isoformat(),\n",
    "        \"level\": \"CRITICAL\",\n",
    "        \"message\": \"Cryptocurrency mining script detected in uploaded file\",\n",
    "        \"source_ip\": \"198.51.100.123\",\n",
    "        \"user_agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "        \"request_id\": \"req-010\",\n",
    "        \"service\": \"file-upload-service\",\n",
    "        \"error_code\": \"MALWARE_DETECTED\",\n",
    "        \"file_hash\": \"a5f3d8b2e9c1a7f4b6e8d2c9a1f5b3e7\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert to DataFrame for easy viewing\n",
    "df_logs = pd.DataFrame(cloudwatch_logs)\n",
    "print(f\"📊 Created {len(df_logs)} CloudWatch log entries\\n\")\n",
    "print(df_logs[['timestamp', 'level', 'service', 'error_code', 'source_ip']].to_string(index=False))\n",
    "print(f\"\\n✅ Dummy CloudWatch logs created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dummy SecurityHub Findings\n",
    "\n",
    "Create realistic AWS SecurityHub findings with various severity levels and security issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy SecurityHub findings\n",
    "security_hub_findings = [\n",
    "    {\n",
    "        \"finding_id\": \"arn:aws:securityhub:us-west-2:123456789012:subscription/aws-foundational-security-best-practices/v/1.0.0/IAM.1/finding/001\",\n",
    "        \"title\": \"IAM.1 - IAM policies should not allow full '*:*' administrative privileges\",\n",
    "        \"severity\": \"CRITICAL\",\n",
    "        \"status\": \"ACTIVE\",\n",
    "        \"resource_type\": \"AwsIamRole\",\n",
    "        \"resource_id\": \"arn:aws:iam::123456789012:role/PowerUserRole\",\n",
    "        \"description\": \"The IAM role PowerUserRole has a policy that grants full administrative privileges\",\n",
    "        \"compliance_status\": \"FAILED\",\n",
    "        \"first_observed\": (base_time - timedelta(days=5)).isoformat(),\n",
    "        \"last_observed\": (base_time + timedelta(minutes=10)).isoformat(),\n",
    "        \"recommendation\": \"Apply least privilege principles and restrict permissions\"\n",
    "    },\n",
    "    {\n",
    "        \"finding_id\": \"arn:aws:securityhub:us-west-2:123456789012:subscription/aws-foundational-security-best-practices/v/1.0.0/S3.1/finding/002\",\n",
    "        \"title\": \"S3.1 - S3 Block Public Access setting should be enabled\",\n",
    "        \"severity\": \"HIGH\",\n",
    "        \"status\": \"ACTIVE\",\n",
    "        \"resource_type\": \"AwsS3Bucket\",\n",
    "        \"resource_id\": \"arn:aws:s3:::sensitive-data-bucket\",\n",
    "        \"description\": \"S3 bucket sensitive-data-bucket does not have Block Public Access enabled\",\n",
    "        \"compliance_status\": \"FAILED\",\n",
    "        \"first_observed\": (base_time - timedelta(days=3)).isoformat(),\n",
    "        \"last_observed\": (base_time + timedelta(minutes=15)).isoformat(),\n",
    "        \"recommendation\": \"Enable S3 Block Public Access at the bucket level\"\n",
    "    },\n",
    "    {\n",
    "        \"finding_id\": \"arn:aws:securityhub:us-west-2:123456789012:subscription/aws-foundational-security-best-practices/v/1.0.0/EC2.2/finding/003\",\n",
    "        \"title\": \"EC2.2 - VPC default security group should not allow inbound and outbound traffic\",\n",
    "        \"severity\": \"HIGH\",\n",
    "        \"status\": \"ACTIVE\",\n",
    "        \"resource_type\": \"AwsEc2SecurityGroup\",\n",
    "        \"resource_id\": \"sg-0abc123def456\",\n",
    "        \"description\": \"Default security group allows unrestricted inbound traffic on port 22\",\n",
    "        \"compliance_status\": \"FAILED\",\n",
    "        \"first_observed\": (base_time - timedelta(days=7)).isoformat(),\n",
    "        \"last_observed\": (base_time + timedelta(minutes=20)).isoformat(),\n",
    "        \"recommendation\": \"Remove all inbound and outbound rules from the default security group\"\n",
    "    },\n",
    "    {\n",
    "        \"finding_id\": \"arn:aws:securityhub:us-west-2:123456789012:subscription/aws-foundational-security-best-practices/v/1.0.0/RDS.1/finding/004\",\n",
    "        \"title\": \"RDS.1 - RDS snapshots should be private\",\n",
    "        \"severity\": \"CRITICAL\",\n",
    "        \"status\": \"ACTIVE\",\n",
    "        \"resource_type\": \"AwsRdsDbSnapshot\",\n",
    "        \"resource_id\": \"arn:aws:rds:us-west-2:123456789012:snapshot:prod-db-snapshot-001\",\n",
    "        \"description\": \"RDS snapshot prod-db-snapshot-001 is publicly accessible\",\n",
    "        \"compliance_status\": \"FAILED\",\n",
    "        \"first_observed\": (base_time - timedelta(hours=12)).isoformat(),\n",
    "        \"last_observed\": (base_time + timedelta(minutes=25)).isoformat(),\n",
    "        \"recommendation\": \"Make the RDS snapshot private immediately\"\n",
    "    },\n",
    "    {\n",
    "        \"finding_id\": \"arn:aws:securityhub:us-west-2:123456789012:subscription/cis-aws-foundations-benchmark/v/1.4.0/2.1.5/finding/005\",\n",
    "        \"title\": \"CIS 2.1.5 - Ensure that S3 buckets have server-side encryption enabled\",\n",
    "        \"severity\": \"MEDIUM\",\n",
    "        \"status\": \"ACTIVE\",\n",
    "        \"resource_type\": \"AwsS3Bucket\",\n",
    "        \"resource_id\": \"arn:aws:s3:::backup-bucket-prod\",\n",
    "        \"description\": \"S3 bucket backup-bucket-prod does not have default encryption enabled\",\n",
    "        \"compliance_status\": \"FAILED\",\n",
    "        \"first_observed\": (base_time - timedelta(days=2)).isoformat(),\n",
    "        \"last_observed\": (base_time + timedelta(minutes=30)).isoformat(),\n",
    "        \"recommendation\": \"Enable default server-side encryption for the S3 bucket\"\n",
    "    },\n",
    "    {\n",
    "        \"finding_id\": \"arn:aws:securityhub:us-west-2:123456789012:subscription/aws-foundational-security-best-practices/v/1.0.0/CloudTrail.1/finding/006\",\n",
    "        \"title\": \"CloudTrail.1 - CloudTrail should be enabled and configured with at least one multi-Region trail\",\n",
    "        \"severity\": \"HIGH\",\n",
    "        \"status\": \"RESOLVED\",\n",
    "        \"resource_type\": \"AwsAccount\",\n",
    "        \"resource_id\": \"arn:aws:iam::123456789012:root\",\n",
    "        \"description\": \"CloudTrail is not enabled in this account\",\n",
    "        \"compliance_status\": \"PASSED\",\n",
    "        \"first_observed\": (base_time - timedelta(days=10)).isoformat(),\n",
    "        \"last_observed\": (base_time - timedelta(days=1)).isoformat(),\n",
    "        \"recommendation\": \"CloudTrail has been enabled - no action needed\"\n",
    "    },\n",
    "    {\n",
    "        \"finding_id\": \"arn:aws:securityhub:us-west-2:123456789012:subscription/aws-foundational-security-best-practices/v/1.0.0/Lambda.1/finding/007\",\n",
    "        \"title\": \"Lambda.1 - Lambda functions should prohibit public access\",\n",
    "        \"severity\": \"CRITICAL\",\n",
    "        \"status\": \"ACTIVE\",\n",
    "        \"resource_type\": \"AwsLambdaFunction\",\n",
    "        \"resource_id\": \"arn:aws:lambda:us-west-2:123456789012:function:DataProcessingFunction\",\n",
    "        \"description\": \"Lambda function DataProcessingFunction allows public invocation\",\n",
    "        \"compliance_status\": \"FAILED\",\n",
    "        \"first_observed\": (base_time - timedelta(hours=6)).isoformat(),\n",
    "        \"last_observed\": (base_time + timedelta(minutes=40)).isoformat(),\n",
    "        \"recommendation\": \"Remove the public access policy from the Lambda function\"\n",
    "    },\n",
    "    {\n",
    "        \"finding_id\": \"arn:aws:securityhub:us-west-2:123456789012:subscription/aws-foundational-security-best-practices/v/1.0.0/GuardDuty.1/finding/008\",\n",
    "        \"title\": \"GuardDuty.1 - GuardDuty should be enabled\",\n",
    "        \"severity\": \"HIGH\",\n",
    "        \"status\": \"ACTIVE\",\n",
    "        \"resource_type\": \"AwsAccount\",\n",
    "        \"resource_id\": \"arn:aws:iam::123456789012:root\",\n",
    "        \"description\": \"GuardDuty is not enabled in us-west-2 region\",\n",
    "        \"compliance_status\": \"FAILED\",\n",
    "        \"first_observed\": (base_time - timedelta(days=30)).isoformat(),\n",
    "        \"last_observed\": (base_time + timedelta(minutes=45)).isoformat(),\n",
    "        \"recommendation\": \"Enable AWS GuardDuty for threat detection\"\n",
    "    },\n",
    "    {\n",
    "        \"finding_id\": \"arn:aws:securityhub:us-west-2:123456789012:subscription/aws-foundational-security-best-practices/v/1.0.0/KMS.1/finding/009\",\n",
    "        \"title\": \"KMS.1 - IAM customer managed policies should not allow decryption actions on all KMS keys\",\n",
    "        \"severity\": \"MEDIUM\",\n",
    "        \"status\": \"ACTIVE\",\n",
    "        \"resource_type\": \"AwsIamPolicy\",\n",
    "        \"resource_id\": \"arn:aws:iam::123456789012:policy/DeveloperPolicy\",\n",
    "        \"description\": \"IAM policy allows kms:Decrypt on all KMS keys\",\n",
    "        \"compliance_status\": \"FAILED\",\n",
    "        \"first_observed\": (base_time - timedelta(days=15)).isoformat(),\n",
    "        \"last_observed\": (base_time + timedelta(minutes=50)).isoformat(),\n",
    "        \"recommendation\": \"Restrict KMS decrypt permissions to specific keys\"\n",
    "    },\n",
    "    {\n",
    "        \"finding_id\": \"arn:aws:securityhub:us-west-2:123456789012:subscription/aws-foundational-security-best-practices/v/1.0.0/EC2.8/finding/010\",\n",
    "        \"title\": \"EC2.8 - EC2 instances should use IMDSv2\",\n",
    "        \"severity\": \"HIGH\",\n",
    "        \"status\": \"ACTIVE\",\n",
    "        \"resource_type\": \"AwsEc2Instance\",\n",
    "        \"resource_id\": \"i-0abc123def456789\",\n",
    "        \"description\": \"EC2 instance is using IMDSv1 which is vulnerable to SSRF attacks\",\n",
    "        \"compliance_status\": \"FAILED\",\n",
    "        \"first_observed\": (base_time - timedelta(days=1)).isoformat(),\n",
    "        \"last_observed\": (base_time + timedelta(minutes=55)).isoformat(),\n",
    "        \"recommendation\": \"Configure instance to require IMDSv2\"\n",
    "    },\n",
    "    {\n",
    "        \"finding_id\": \"arn:aws:securityhub:us-west-2:123456789012:subscription/aws-foundational-security-best-practices/v/1.0.0/SecretsManager.1/finding/011\",\n",
    "        \"title\": \"SecretsManager.1 - Secrets Manager secrets should have automatic rotation enabled\",\n",
    "        \"severity\": \"MEDIUM\",\n",
    "        \"status\": \"ACTIVE\",\n",
    "        \"resource_type\": \"AwsSecretsManagerSecret\",\n",
    "        \"resource_id\": \"arn:aws:secretsmanager:us-west-2:123456789012:secret:prod/database/password\",\n",
    "        \"description\": \"Secret prod/database/password does not have automatic rotation enabled\",\n",
    "        \"compliance_status\": \"FAILED\",\n",
    "        \"first_observed\": (base_time - timedelta(days=20)).isoformat(),\n",
    "        \"last_observed\": (base_time + timedelta(hours=1)).isoformat(),\n",
    "        \"recommendation\": \"Enable automatic rotation for this secret\"\n",
    "    },\n",
    "    {\n",
    "        \"finding_id\": \"arn:aws:securityhub:us-west-2:123456789012:subscription/aws-foundational-security-best-practices/v/1.0.0/ELB.1/finding/012\",\n",
    "        \"title\": \"ELB.1 - Application Load Balancer should be configured to redirect HTTP to HTTPS\",\n",
    "        \"severity\": \"MEDIUM\",\n",
    "        \"status\": \"ACTIVE\",\n",
    "        \"resource_type\": \"AwsElbv2LoadBalancer\",\n",
    "        \"resource_id\": \"arn:aws:elasticloadbalancing:us-west-2:123456789012:loadbalancer/app/prod-alb/abc123\",\n",
    "        \"description\": \"Load balancer accepts HTTP traffic without redirecting to HTTPS\",\n",
    "        \"compliance_status\": \"FAILED\",\n",
    "        \"first_observed\": (base_time - timedelta(days=4)).isoformat(),\n",
    "        \"last_observed\": (base_time + timedelta(hours=1, minutes=5)).isoformat(),\n",
    "        \"recommendation\": \"Configure HTTP to HTTPS redirect rule\"\n",
    "    },\n",
    "    {\n",
    "        \"finding_id\": \"arn:aws:securityhub:us-west-2:123456789012:subscription/pci-dss/v/3.2.1/PCI.IAM.7/finding/013\",\n",
    "        \"title\": \"PCI.IAM.7 - IAM user credentials unused for 90 days should be disabled\",\n",
    "        \"severity\": \"LOW\",\n",
    "        \"status\": \"ACTIVE\",\n",
    "        \"resource_type\": \"AwsIamUser\",\n",
    "        \"resource_id\": \"arn:aws:iam::123456789012:user/john.doe\",\n",
    "        \"description\": \"IAM user john.doe has not been used for 127 days\",\n",
    "        \"compliance_status\": \"FAILED\",\n",
    "        \"first_observed\": (base_time - timedelta(days=37)).isoformat(),\n",
    "        \"last_observed\": (base_time + timedelta(hours=1, minutes=10)).isoformat(),\n",
    "        \"recommendation\": \"Disable or remove inactive IAM user\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_findings = pd.DataFrame(security_hub_findings)\n",
    "print(f\"🔒 Created {len(df_findings)} SecurityHub findings\\n\")\n",
    "print(df_findings[['title', 'severity', 'status', 'resource_type']].to_string(index=False))\n",
    "\n",
    "# Show severity distribution\n",
    "print(f\"\\n📊 Severity Distribution:\")\n",
    "print(df_findings['severity'].value_counts().to_string())\n",
    "print(f\"\\n✅ Dummy SecurityHub findings created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Time-Series Metrics Data\n",
    "\n",
    "Generate realistic time-series data for error rates and latency metrics showing normal patterns and anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate time-series metrics data (last 2 hours, 5-minute intervals)\n",
    "time_points = pd.date_range(end=datetime.now(), periods=24, freq='5T')\n",
    "\n",
    "# Error rate (requests per minute) - baseline ~5, anomaly spike to 45\n",
    "np.random.seed(42)\n",
    "error_rates = []\n",
    "for i, t in enumerate(time_points):\n",
    "    if i < 10:  # Normal period\n",
    "        error_rates.append(max(0, np.random.normal(5, 1.5)))\n",
    "    elif i < 13:  # Anomaly spike (corresponds to attack time)\n",
    "        error_rates.append(max(0, np.random.normal(45, 8)))\n",
    "    else:  # Recovery period\n",
    "        error_rates.append(max(0, np.random.normal(7, 2)))\n",
    "\n",
    "# Latency (milliseconds) - baseline ~150ms, anomaly spike to ~2500ms\n",
    "latencies = []\n",
    "for i, t in enumerate(time_points):\n",
    "    if i < 10:  # Normal period\n",
    "        latencies.append(max(50, np.random.normal(150, 30)))\n",
    "    elif i < 13:  # Anomaly spike\n",
    "        latencies.append(max(500, np.random.normal(2500, 400)))\n",
    "    elif i < 16:  # Recovery period\n",
    "        latencies.append(max(200, np.random.normal(800, 150)))\n",
    "    else:  # Back to normal\n",
    "        latencies.append(max(50, np.random.normal(180, 35)))\n",
    "\n",
    "# Create DataFrame\n",
    "df_metrics = pd.DataFrame({\n",
    "    'timestamp': time_points,\n",
    "    'error_rate': error_rates,\n",
    "    'latency_ms': latencies,\n",
    "    'service': 'api-gateway'\n",
    "})\n",
    "\n",
    "print(f\"📈 Created time-series metrics data\\n\")\n",
    "print(df_metrics.to_string(index=False))\n",
    "\n",
    "# Show statistics\n",
    "print(f\"\\n📊 Metrics Summary:\")\n",
    "print(f\"Error Rate - Mean: {df_metrics['error_rate'].mean():.2f}, Max: {df_metrics['error_rate'].max():.2f}\")\n",
    "print(f\"Latency - Mean: {df_metrics['latency_ms'].mean():.2f}ms, Max: {df_metrics['latency_ms'].max():.2f}ms\")\n",
    "print(f\"\\n✅ Time-series metrics created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Tool Functions\n",
    "\n",
    "Create tool functions that the agent can use to query our dummy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool function definitions with @tool decorator\n",
    "\n",
    "@tool\n",
    "def query_cloudwatch_logs(severity: str = None, service: str = None, source_ip: str = None, limit: int = 10) -> str:\n",
    "    \"\"\"\n",
    "    Query CloudWatch logs with optional filters.\n",
    "    \n",
    "    Args:\n",
    "        severity: Filter by log level (ERROR, WARNING, CRITICAL)\n",
    "        service: Filter by service name\n",
    "        source_ip: Filter by source IP address\n",
    "        limit: Maximum number of results to return\n",
    "    \n",
    "    Returns:\n",
    "        JSON string containing matching log entries\n",
    "    \"\"\"\n",
    "    filtered_logs = cloudwatch_logs.copy()\n",
    "    \n",
    "    if severity:\n",
    "        filtered_logs = [log for log in filtered_logs if log['level'] == severity.upper()]\n",
    "    if service:\n",
    "        filtered_logs = [log for log in filtered_logs if log['service'] == service]\n",
    "    if source_ip:\n",
    "        filtered_logs = [log for log in filtered_logs if log['source_ip'] == source_ip]\n",
    "    \n",
    "    result = filtered_logs[:limit]\n",
    "    return json.dumps(result, indent=2)\n",
    "\n",
    "\n",
    "@tool\n",
    "def query_security_hub_findings(severity: str = None, status: str = \"ACTIVE\", resource_type: str = None, limit: int = 10) -> str:\n",
    "    \"\"\"\n",
    "    Query SecurityHub findings with optional filters.\n",
    "    \n",
    "    Args:\n",
    "        severity: Filter by severity (CRITICAL, HIGH, MEDIUM, LOW)\n",
    "        status: Filter by status (ACTIVE, RESOLVED)\n",
    "        resource_type: Filter by AWS resource type\n",
    "        limit: Maximum number of results to return\n",
    "    \n",
    "    Returns:\n",
    "        JSON string containing matching findings\n",
    "    \"\"\"\n",
    "    filtered_findings = security_hub_findings.copy()\n",
    "    \n",
    "    if severity:\n",
    "        filtered_findings = [f for f in filtered_findings if f['severity'] == severity.upper()]\n",
    "    if status:\n",
    "        filtered_findings = [f for f in filtered_findings if f['status'] == status.upper()]\n",
    "    if resource_type:\n",
    "        filtered_findings = [f for f in filtered_findings if f['resource_type'] == resource_type]\n",
    "    \n",
    "    result = filtered_findings[:limit]\n",
    "    return json.dumps(result, indent=2)\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_metrics_for_timerange(start_time: str = None, end_time: str = None, service: str = \"api-gateway\") -> str:\n",
    "    \"\"\"\n",
    "    Get CloudWatch metrics for a specific time range.\n",
    "    \n",
    "    Args:\n",
    "        start_time: Start time in ISO format (optional)\n",
    "        end_time: End time in ISO format (optional)\n",
    "        service: Service name to query metrics for\n",
    "    \n",
    "    Returns:\n",
    "        JSON string containing time-series metrics data\n",
    "    \"\"\"\n",
    "    filtered_metrics = df_metrics[df_metrics['service'] == service].copy()\n",
    "    \n",
    "    if start_time:\n",
    "        filtered_metrics = filtered_metrics[filtered_metrics['timestamp'] >= pd.to_datetime(start_time)]\n",
    "    if end_time:\n",
    "        filtered_metrics = filtered_metrics[filtered_metrics['timestamp'] <= pd.to_datetime(end_time)]\n",
    "    \n",
    "    # Convert to dict for JSON serialization\n",
    "    result = filtered_metrics.to_dict(orient='records')\n",
    "    # Convert timestamps to strings\n",
    "    for record in result:\n",
    "        record['timestamp'] = record['timestamp'].isoformat()\n",
    "    \n",
    "    return json.dumps(result, indent=2)\n",
    "\n",
    "\n",
    "@tool\n",
    "def analyze_ip_address(ip_address: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyze an IP address to determine if it's suspicious and provide context.\n",
    "    \n",
    "    Args:\n",
    "        ip_address: IP address to analyze\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with IP analysis results\n",
    "    \"\"\"\n",
    "    # Count occurrences in logs\n",
    "    occurrences = sum(1 for log in cloudwatch_logs if log['source_ip'] == ip_address)\n",
    "    \n",
    "    # Get all log entries for this IP\n",
    "    ip_logs = [log for log in cloudwatch_logs if log['source_ip'] == ip_address]\n",
    "    \n",
    "    # Determine if suspicious (simplified heuristic)\n",
    "    error_count = sum(1 for log in ip_logs if log['level'] in ['ERROR', 'CRITICAL'])\n",
    "    is_suspicious = error_count >= 2 or occurrences >= 3\n",
    "    \n",
    "    # Check if it's a known malicious IP range (simplified check)\n",
    "    is_tor_exit = ip_address.startswith('185.220.')\n",
    "    \n",
    "    result = {\n",
    "        \"ip_address\": ip_address,\n",
    "        \"total_requests\": occurrences,\n",
    "        \"error_count\": error_count,\n",
    "        \"is_suspicious\": is_suspicious,\n",
    "        \"is_known_malicious\": is_tor_exit,\n",
    "        \"risk_level\": \"HIGH\" if is_suspicious and is_tor_exit else \"MEDIUM\" if is_suspicious else \"LOW\",\n",
    "        \"services_accessed\": list(set(log['service'] for log in ip_logs)),\n",
    "        \"recent_activity\": ip_logs[-3:] if ip_logs else []\n",
    "    }\n",
    "    \n",
    "    return json.dumps(result, indent=2)\n",
    "\n",
    "\n",
    "# Test the tool functions\n",
    "print(\"🔧 Tool Functions Implemented:\\n\")\n",
    "print(\"1. query_cloudwatch_logs(severity, service, source_ip, limit)\")\n",
    "print(\"2. query_security_hub_findings(severity, status, resource_type, limit)\")\n",
    "print(\"3. get_metrics_for_timerange(start_time, end_time, service)\")\n",
    "print(\"4. analyze_ip_address(ip_address)\")\n",
    "print(\"\\n✅ All tool functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Query Metrics Tool Directly\n",
    "\n",
    "Before setting up agents, let's see how the metrics tool works by calling it directly to detect anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the metrics tool directly\n",
    "print(\"Testing get_metrics_for_timerange tool...\\n\")\n",
    "\n",
    "# Get all metrics for api-gateway\n",
    "metrics_json = get_metrics_for_timerange(service=\"api-gateway\")\n",
    "metrics_data = json.loads(metrics_json)\n",
    "\n",
    "print(f\"Retrieved {len(metrics_data)} data points\\n\")\n",
    "\n",
    "# Find the anomaly spike\n",
    "print(\"Looking for anomalies...\\n\")\n",
    "for point in metrics_data:\n",
    "    if point['error_rate'] > 40 or point['latency_ms'] > 2000:\n",
    "        print(f\"🚨 ANOMALY DETECTED:\")\n",
    "        print(f\"   Timestamp: {point['timestamp']}\")\n",
    "        print(f\"   Error Rate: {point['error_rate']:.2f} req/min (baseline ~5)\")\n",
    "        print(f\"   Latency: {point['latency_ms']:.2f}ms (baseline ~150ms)\")\n",
    "        print()\n",
    "\n",
    "print(\"✅ The metrics show clear anomaly spikes that agents can detect!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Bedrock Model with Pixtral Large\n",
    "\n",
    "Configure the Pixtral Large model for use with Strands Agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BedrockModel instance with Pixtral Large\n",
    "model_id = \"us.mistral.pixtral-large-2502-v1:0\"\n",
    "\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=model_id,\n",
    "    streaming=False\n",
    ")\n",
    "\n",
    "# Initialize Bedrock client for cost calculation\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "print(f\"✅ BedrockModel configured with {model_id}\")\n",
    "print(f\"📋 Tools available for agent: query_cloudwatch_logs, query_security_hub_findings, get_metrics_for_timerange, analyze_ip_address\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Security Agent Function\n",
    "\n",
    "Now we'll create the main agent execution function that:\n",
    "- Initializes a Strands Agent with our Pixtral Large model\n",
    "- Configures the agent with our security analysis tool functions\n",
    "- Executes security investigations and tracks execution time\n",
    "- Returns comprehensive analysis with remediation recommendations\n",
    "\n",
    "The agent will automatically:\n",
    "1. Understand the user's security query\n",
    "2. Call the appropriate tool functions to gather data\n",
    "3. Analyze the results across multiple data sources\n",
    "4. Provide actionable security insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent execution function with Strands Agents and cost tracking\n",
    "def run_security_agent(user_query: str):\n",
    "    \"\"\"\n",
    "    Run the security analysis agent with Pixtral Large using Strands Agents.\n",
    "    \n",
    "    Args:\n",
    "        user_query: The investigation query from the user\n",
    "    \n",
    "    Returns:\n",
    "        Agent response and cost information\n",
    "    \"\"\"\n",
    "    # Define system prompt\n",
    "    system_prompt = \"\"\"You are a security analyst AI assistant with access to CloudWatch logs, SecurityHub findings, and metrics data.\n",
    "\n",
    "Your role is to:\n",
    "1. Investigate security incidents by analyzing logs and findings\n",
    "2. Identify patterns and anomalies in the data\n",
    "3. Correlate events across different data sources\n",
    "4. Provide clear, actionable security recommendations\n",
    "5. Explain your reasoning step-by-step\n",
    "\n",
    "When investigating:\n",
    "- Start by querying relevant logs and findings\n",
    "- Look for suspicious IPs, repeated failures, and security violations\n",
    "- Check metrics for anomalies during incident timeframes\n",
    "- Analyze the severity and impact of findings\n",
    "- Provide a comprehensive summary with remediation steps\n",
    "\n",
    "Be thorough but concise. Use the available tools to gather evidence before drawing conclusions.\"\"\"\n",
    "    \n",
    "    # Create tools list\n",
    "    tools = [\n",
    "        query_cloudwatch_logs,\n",
    "        query_security_hub_findings,\n",
    "        get_metrics_for_timerange,\n",
    "        analyze_ip_address\n",
    "    ]\n",
    "    \n",
    "    # Create agent\n",
    "    agent = Agent(\n",
    "        model=bedrock_model,\n",
    "        tools=tools,\n",
    "        system_prompt=system_prompt\n",
    "    )\n",
    "    \n",
    "    print(f\"🤖 Starting investigation with Pixtral Large...\")\n",
    "    print(f\"📝 Query: {user_query}\\n\")\n",
    "    \n",
    "    # Track start time for approximate cost calculation\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Run agent\n",
    "    response = agent(user_query)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"💬 Agent Response:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(response)\n",
    "    \n",
    "    # Note: Strands Agent doesn't expose token usage directly in the response\n",
    "    # For accurate cost tracking, you would need to access the underlying model's usage stats\n",
    "    # This is a simplified cost estimation\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"⏱️  Execution Time: {end_time - start_time:.2f}s\")\n",
    "    print(f\"💰 Note: For detailed token usage and costs, check CloudWatch Logs or Bedrock metrics\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return {\n",
    "        \"response\": response,\n",
    "        \"execution_time\": end_time - start_time\n",
    "    }\n",
    "\n",
    "print(\"✅ Agent execution function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Multi-Agent Security Investigation Workflow\n",
    "\n",
    "Instead of making simple single-agent calls, we can create a sophisticated **multi-agent workflow** that orchestrates multiple specialized agents to perform comprehensive security investigations. This workflow demonstrates production-ready patterns for building complex agentic systems.\n",
    "\n",
    "### Why Multi-Agent Workflows?\n",
    "\n",
    "**Single-Agent Limitations:**\n",
    "- One agent tries to do everything\n",
    "- Generic prompts lead to unfocused analysis\n",
    "- No specialization or deep expertise\n",
    "- Difficult to manage complexity\n",
    "\n",
    "**Multi-Agent Benefits:**\n",
    "- **Specialization**: Each agent focuses on specific domain (logs, compliance, metrics)\n",
    "- **Modularity**: Easy to add, remove, or modify individual agents\n",
    "- **Scalability**: Distribute work across multiple focused agents\n",
    "- **Quality**: Specialized prompts and tools yield better results\n",
    "\n",
    "### Workflow Capabilities\n",
    "\n",
    "This workflow demonstrates:\n",
    "\n",
    "1. **Intelligent Routing** - Triage agent classifies investigation type and determines which specialists to invoke\n",
    "2. **Sequential Execution** - Each agent builds upon previous findings in a coordinated manner\n",
    "3. **Conditional Logic** - Workflow adapts based on investigation type (log_analysis, compliance_review, metrics_analysis, full_audit)\n",
    "4. **State Management** - Tracks all findings across the workflow for comprehensive synthesis\n",
    "5. **Synthesis** - Final remediation agent combines insights from all specialists into prioritized action plans\n",
    "\n",
    "### Workflow Architecture\n",
    "\n",
    "Our security workflow consists of 5 specialized agents:\n",
    "- **Triage Agent**: Analyzes the query and determines which specialized agents to invoke\n",
    "- **Log Analysis Agent**: Examines CloudWatch logs for security events (tools: query_cloudwatch_logs, analyze_ip_address)\n",
    "- **Compliance Agent**: Reviews SecurityHub findings and compliance violations (tool: query_security_hub_findings)\n",
    "- **Metrics Agent**: Detects anomalies in performance metrics (tool: get_metrics_for_timerange)\n",
    "- **Remediation Agent**: Synthesizes all findings and provides prioritized action plans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow State Management\n",
    "\n",
    "Define the state object that tracks the investigation workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow State Management\n",
    "from typing import List, Dict, Any\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class SecurityWorkflowState:\n",
    "    \"\"\"State object that tracks the security investigation workflow\"\"\"\n",
    "    query: str\n",
    "    investigation_type: str = \"\"  # triage, log_analysis, compliance, full_audit, etc.\n",
    "    \n",
    "    # Agent results\n",
    "    log_findings: List[Dict] = field(default_factory=list)\n",
    "    compliance_findings: List[Dict] = field(default_factory=list)\n",
    "    metrics_analysis: Dict = field(default_factory=dict)\n",
    "    threat_intelligence: Dict = field(default_factory=dict)\n",
    "    \n",
    "    # Final output\n",
    "    remediation_plan: str = \"\"\n",
    "    priority_actions: List[str] = field(default_factory=list)\n",
    "    \n",
    "    # Workflow tracking\n",
    "    agents_invoked: List[str] = field(default_factory=list)\n",
    "    execution_time: float = 0.0\n",
    "\n",
    "print(\"✅ Workflow state management ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specialized Security Agents\n",
    "\n",
    "Create specialized agents for different aspects of security analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specialized Security Agents\n",
    "\n",
    "def create_triage_agent():\n",
    "    \"\"\"Agent that determines investigation type and routing\"\"\"\n",
    "    system_prompt = \"\"\"You are a security triage specialist. Analyze the user's query and determine:\n",
    "    1. Investigation type (log_analysis, compliance_review, metrics_analysis, threat_investigation, full_audit)\n",
    "    2. Which specialized agents should be invoked\n",
    "    3. The order of agent execution\n",
    "    \n",
    "    Respond with a brief classification and reasoning.\"\"\"\n",
    "    \n",
    "    tools = []  # Triage agent doesn't need tools, just classification\n",
    "    agent = Agent(model=bedrock_model, tools=tools, system_prompt=system_prompt)\n",
    "    return agent\n",
    "\n",
    "def create_log_analysis_agent():\n",
    "    \"\"\"Agent specialized in CloudWatch log analysis\"\"\"\n",
    "    system_prompt = \"\"\"You are a log analysis specialist. Your role:\n",
    "    1. Query CloudWatch logs for security events\n",
    "    2. Identify suspicious patterns (failed auth, SQL injection, malware, etc.)\n",
    "    3. Extract relevant IPs and services\n",
    "    4. Provide severity assessment\n",
    "    \n",
    "    Be thorough and identify ALL security-relevant events.\"\"\"\n",
    "    \n",
    "    tools = [query_cloudwatch_logs, analyze_ip_address]\n",
    "    agent = Agent(model=bedrock_model, tools=tools, system_prompt=system_prompt)\n",
    "    return agent\n",
    "\n",
    "def create_compliance_agent():\n",
    "    \"\"\"Agent specialized in SecurityHub compliance review\"\"\"\n",
    "    system_prompt = \"\"\"You are a compliance and security findings specialist. Your role:\n",
    "    1. Query SecurityHub findings\n",
    "    2. Prioritize by severity and impact\n",
    "    3. Identify compliance violations\n",
    "    4. Assess risk levels\n",
    "    \n",
    "    Focus on CRITICAL and HIGH severity findings first.\"\"\"\n",
    "    \n",
    "    tools = [query_security_hub_findings]\n",
    "    agent = Agent(model=bedrock_model, tools=tools, system_prompt=system_prompt)\n",
    "    return agent\n",
    "\n",
    "def create_metrics_agent():\n",
    "    \"\"\"Agent specialized in metrics anomaly detection\"\"\"\n",
    "    system_prompt = \"\"\"You are a metrics analysis specialist. Your role:\n",
    "    1. Analyze time-series metrics for anomalies\n",
    "    2. Identify performance degradation patterns\n",
    "    3. Correlate metrics spikes with security events\n",
    "    4. Detect potential DDoS or resource exhaustion attacks\n",
    "    \n",
    "    Look for statistically significant deviations from baseline.\"\"\"\n",
    "    \n",
    "    tools = [get_metrics_for_timerange]\n",
    "    agent = Agent(model=bedrock_model, tools=tools, system_prompt=system_prompt)\n",
    "    return agent\n",
    "\n",
    "def create_remediation_agent():\n",
    "    \"\"\"Agent that synthesizes findings and creates action plans\"\"\"\n",
    "    system_prompt = \"\"\"You are a security remediation specialist. Your role:\n",
    "    1. Synthesize findings from all agents\n",
    "    2. Create a prioritized remediation plan\n",
    "    3. Provide specific, actionable steps\n",
    "    4. Estimate impact and urgency\n",
    "    \n",
    "    Structure your output as:\n",
    "    - Executive Summary\n",
    "    - Priority 1 Actions (immediate)\n",
    "    - Priority 2 Actions (short-term)\n",
    "    - Priority 3 Actions (long-term)\n",
    "    - Recommended monitoring\"\"\"\n",
    "    \n",
    "    tools = []  # Remediation agent synthesizes, doesn't need tools\n",
    "    agent = Agent(model=bedrock_model, tools=tools, system_prompt=system_prompt)\n",
    "    return agent\n",
    "\n",
    "print(\"✅ Specialized security agents created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Orchestration\n",
    "\n",
    "The orchestrator manages the sequential execution of specialized agents based on the investigation type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Security Investigation Workflow Orchestrator\n",
    "\n",
    "def run_security_workflow(user_query: str) -> SecurityWorkflowState:\n",
    "    \"\"\"\n",
    "    Orchestrates a multi-agent security investigation workflow.\n",
    "    \n",
    "    Workflow Steps:\n",
    "    1. Triage - Classify the investigation type\n",
    "    2. Routing - Determine which agents to invoke\n",
    "    3. Specialized Analysis - Run appropriate agents in sequence\n",
    "    4. Synthesis - Combine findings into actionable insights\n",
    "    \n",
    "    Args:\n",
    "        user_query: The security investigation request\n",
    "        \n",
    "    Returns:\n",
    "        SecurityWorkflowState with complete investigation results\n",
    "    \"\"\"\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Initialize state\n",
    "    state = SecurityWorkflowState(query=user_query)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"🔍 SECURITY INVESTIGATION WORKFLOW\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Query: {user_query}\\n\")\n",
    "    \n",
    "    # STEP 1: Triage\n",
    "    print(\"\\n📋 STEP 1: Triage Analysis\")\n",
    "    print(\"-\"*80)\n",
    "    triage_agent = create_triage_agent()\n",
    "    triage_response = triage_agent(user_query)\n",
    "    state.agents_invoked.append(\"triage\")\n",
    "    \n",
    "    # Show abbreviated triage response\n",
    "    triage_str = str(triage_response)\n",
    "    if len(triage_str) > 200:\n",
    "        print(f\"Triage Result: {triage_str[:200]}... [truncated]\")\n",
    "    else:\n",
    "        print(f\"Triage Result: {triage_str}\")\n",
    "    \n",
    "    # Determine investigation type from triage response\n",
    "    triage_lower = triage_str.lower()\n",
    "    if \"full\" in triage_lower or \"comprehensive\" in triage_lower or \"audit\" in triage_lower:\n",
    "        state.investigation_type = \"full_audit\"\n",
    "    elif \"compliance\" in triage_lower or \"securityhub\" in triage_lower or \"findings\" in triage_lower:\n",
    "        state.investigation_type = \"compliance_review\"\n",
    "    elif \"metrics\" in triage_lower or \"performance\" in triage_lower or \"anomaly\" in triage_lower:\n",
    "        state.investigation_type = \"metrics_analysis\"\n",
    "    elif \"log\" in triage_lower or \"authentication\" in triage_lower or \"attack\" in triage_lower:\n",
    "        state.investigation_type = \"log_analysis\"\n",
    "    else:\n",
    "        state.investigation_type = \"full_audit\"  # Default to comprehensive\n",
    "    \n",
    "    print(f\"\\n🎯 Investigation Type: {state.investigation_type}\")\n",
    "    \n",
    "    # STEP 2 & 3: Execute specialized agents based on investigation type\n",
    "    if state.investigation_type in [\"log_analysis\", \"full_audit\"]:\n",
    "        print(\"\\n\\n🔎 STEP 2: Log Analysis\")\n",
    "        print(\"-\"*80)\n",
    "        log_agent = create_log_analysis_agent()\n",
    "        log_query = \"Analyze all CloudWatch logs for security events, suspicious IPs, and attack patterns.\"\n",
    "        log_response = log_agent(log_query)\n",
    "        state.agents_invoked.append(\"log_analysis\")\n",
    "        \n",
    "        # Show key findings only\n",
    "        log_str = str(log_response)\n",
    "        print(f\"✓ Log analysis completed ({len(log_str)} chars)\")\n",
    "        state.log_findings.append({\"analysis\": log_str})\n",
    "    \n",
    "    if state.investigation_type in [\"compliance_review\", \"full_audit\"]:\n",
    "        print(\"\\n\\n🛡️  STEP 3: Compliance Review\")\n",
    "        print(\"-\"*80)\n",
    "        compliance_agent = create_compliance_agent()\n",
    "        compliance_query = \"Review all CRITICAL and HIGH severity SecurityHub findings and assess compliance risks.\"\n",
    "        compliance_response = compliance_agent(compliance_query)\n",
    "        state.agents_invoked.append(\"compliance\")\n",
    "        \n",
    "        # Show key findings only\n",
    "        compliance_str = str(compliance_response)\n",
    "        print(f\"✓ Compliance review completed ({len(compliance_str)} chars)\")\n",
    "        state.compliance_findings.append({\"analysis\": compliance_str})\n",
    "    \n",
    "    if state.investigation_type in [\"metrics_analysis\", \"full_audit\"]:\n",
    "        print(\"\\n\\n📊 STEP 4: Metrics Analysis\")\n",
    "        print(\"-\"*80)\n",
    "        metrics_agent = create_metrics_agent()\n",
    "        metrics_query = \"Analyze metrics for api-gateway service to detect anomalies and correlate with security events.\"\n",
    "        metrics_response = metrics_agent(metrics_query)\n",
    "        state.agents_invoked.append(\"metrics\")\n",
    "        \n",
    "        # Show key findings only\n",
    "        metrics_str = str(metrics_response)\n",
    "        print(f\"✓ Metrics analysis completed ({len(metrics_str)} chars)\")\n",
    "        state.metrics_analysis = {\"analysis\": metrics_str}\n",
    "    \n",
    "    # STEP 5: Remediation & Synthesis\n",
    "    print(\"\\n\\n💡 STEP 5: Remediation Planning\")\n",
    "    print(\"-\"*80)\n",
    "    remediation_agent = create_remediation_agent()\n",
    "    \n",
    "    # Build context from all agent findings\n",
    "    synthesis_context = f\"\"\"Based on the following security investigation findings:\n",
    "\n",
    "USER QUERY: {user_query}\n",
    "\n",
    "LOG ANALYSIS:\n",
    "{state.log_findings if state.log_findings else \"Not performed\"}\n",
    "\n",
    "COMPLIANCE REVIEW:\n",
    "{state.compliance_findings if state.compliance_findings else \"Not performed\"}\n",
    "\n",
    "METRICS ANALYSIS:\n",
    "{state.metrics_analysis if state.metrics_analysis else \"Not performed\"}\n",
    "\n",
    "Provide a comprehensive remediation plan with prioritized actions.\"\"\"\n",
    "    \n",
    "    remediation_response = remediation_agent(synthesis_context)\n",
    "    state.agents_invoked.append(\"remediation\")\n",
    "    state.remediation_plan = str(remediation_response)\n",
    "    \n",
    "    # Calculate execution time\n",
    "    state.execution_time = time.time() - start_time\n",
    "    \n",
    "    # Final output - formatted nicely\n",
    "    print(\"\\n\\n\" + \"=\"*80)\n",
    "    print(\"📝 FINAL REMEDIATION PLAN\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Format the remediation plan for better readability\n",
    "    plan_lines = state.remediation_plan.split('\\n')\n",
    "    for line in plan_lines:\n",
    "        if line.strip():\n",
    "            # Add extra spacing for section headers\n",
    "            if any(keyword in line for keyword in ['Executive Summary', 'Priority 1', 'Priority 2', 'Priority 3', 'Recommended']):\n",
    "                print(f\"\\n{line}\")\n",
    "            else:\n",
    "                print(line)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"📊 WORKFLOW SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Investigation Type: {state.investigation_type}\")\n",
    "    print(f\"Agents Invoked: {', '.join(state.agents_invoked)}\")\n",
    "    print(f\"Total Execution Time: {state.execution_time:.2f}s\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"✅ Workflow orchestrator ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 1: Triage Agent\n",
    "\n",
    "See how the triage agent classifies different types of security queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Triage Agent\n",
    "print(\"Testing Triage Agent...\\n\")\n",
    "triage_agent = create_triage_agent()\n",
    "\n",
    "# Test query\n",
    "test_query = \"Check for failed authentication attempts in our logs\"\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "\n",
    "response = triage_agent(test_query)\n",
    "print(f\"\\nTriage Classification:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2: Log Analysis Agent\n",
    "\n",
    "See how the log analysis agent uses tools to investigate CloudWatch logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Log Analysis Agent\n",
    "print(\"Testing Log Analysis Agent...\\n\")\n",
    "log_agent = create_log_analysis_agent()\n",
    "\n",
    "# Test query\n",
    "test_query = \"Find all CRITICAL security events\"\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "\n",
    "response = log_agent(test_query)\n",
    "print(f\"\\nLog Analysis Result:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 3: Compliance Agent\n",
    "\n",
    "See how the compliance agent reviews SecurityHub findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Compliance Agent\n",
    "print(\"Testing Compliance Agent...\\n\")\n",
    "compliance_agent = create_compliance_agent()\n",
    "\n",
    "# Test query\n",
    "test_query = \"Show me all CRITICAL severity findings\"\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "\n",
    "response = compliance_agent(test_query)\n",
    "print(f\"\\nCompliance Review Result:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 4: Metrics Analysis Agent\n",
    "\n",
    "See how the metrics agent detects anomalies in time-series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Metrics Agent\n",
    "print(\"Testing Metrics Analysis Agent...\\n\")\n",
    "metrics_agent = create_metrics_agent()\n",
    "\n",
    "# Test query\n",
    "test_query = \"Analyze the api-gateway metrics for anomalies in the last 2 hours\"\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "\n",
    "response = metrics_agent(test_query)\n",
    "print(f\"\\nMetrics Analysis Result:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Workflow Example: Comprehensive Security Audit\n",
    "\n",
    "Now let's run the complete workflow that orchestrates all agents together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow Example 1: Comprehensive Security Audit\n",
    "workflow_query_1 = \"\"\"Perform a comprehensive security audit of our infrastructure. \n",
    "Analyze logs for attacks, review all compliance findings, check for performance anomalies, \n",
    "and provide a prioritized remediation plan.\"\"\"\n",
    "\n",
    "workflow_result_1 = run_security_workflow(workflow_query_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
